{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting and Classifying Toxic Comments\n",
    "# Part 3: Sequential Binary Classifiers\n",
    "\n",
    "It may be possible to employ sequential binary models in order to get better results with rarer cases.\n",
    "\n",
    "If we first classify Toxic and Not Toxic, we could further process only the Toxic results against models that had been trained only to recognise sub-classes of toxic models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spaCy Setup and Imports\n",
    "\n",
    "This time, we'll only use spaCy for data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "from spacy.lang.en import English\n",
    "spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "from spacy.tokens import Doc\n",
    "# import en_core_web_lg\n",
    "nlp = spacy.load('../models/spacy_multi_cat_model/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Custom Functions\n",
    "\n",
    "I've created a few custom functions to assist in text preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# add src folder to path\n",
    "sys.path.insert(1, '../src')\n",
    "\n",
    "# from text_prep import tidy_series, uppercase_proportion_column\n",
    "from spacy_helper import doc_check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Train & Test Dataframes from Pickle File\n",
    "\n",
    "We've already done a stratified Train Test Split, and a little bit of very basic text processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! ls ../data/basic_df_split/\n",
    "\n",
    "X_train = pd.read_pickle('../data/basic_df_split/basic_X_train.pkl')\n",
    "X_test = pd.read_pickle('../data/basic_df_split/basic_X_test.pkl')\n",
    "y_train = pd.read_pickle('../data/basic_df_split/basic_y_train.pkl')\n",
    "y_test= pd.read_pickle('../data/basic_df_split/basic_y_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 106912 entries, 27301 to 14596\n",
      "Data columns (total 2 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   comment_text          106912 non-null  object \n",
      " 1   uppercase_proportion  106897 non-null  float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 2.4+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(X_train.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 106912 entries, 27301 to 14596\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count   Dtype\n",
      "---  ------         --------------   -----\n",
      " 0   toxic          106912 non-null  int64\n",
      " 1   severe_toxic   106912 non-null  int64\n",
      " 2   obscene        106912 non-null  int64\n",
      " 3   threat         106912 non-null  int64\n",
      " 4   insult         106912 non-null  int64\n",
      " 5   identity_hate  106912 non-null  int64\n",
      "dtypes: int64(6)\n",
      "memory usage: 5.7 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(y_train.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1: Use spaCy for feature reduction\n",
    "\n",
    "We will utilize spaCy to reduce features to:\n",
    "- remove stopwords\n",
    "- remove punctuation\n",
    "- retain only lemmas\n",
    "- render all lemmas to lowercase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1a: testing process with subset of text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create test subset copy\n",
    "text_sub = X_train['comment_text'].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sorry Still can't find your penis?\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_sub.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'spacy.tokens.doc.Doc'>\n"
     ]
    }
   ],
   "source": [
    "test_doc = nlp(text_sub.iloc[0])\n",
    "print(type(test_doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sorry', 'find', 'penis']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmas_lc = [i.lemma_.lower() for i in test_doc if doc_check(i)]\n",
    "lemmas_lc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.08142996e-01,  1.86965004e-01, -3.79616290e-01, -6.50937557e-02,\n",
       "        6.80181161e-02,  1.81352478e-02,  8.92658755e-02, -2.32500494e-01,\n",
       "        3.28790024e-02,  2.19221258e+00, -2.24580005e-01,  3.60621251e-02,\n",
       "        1.41831264e-01, -9.37562287e-02, -2.12733522e-01, -6.34263754e-02,\n",
       "       -9.71264318e-02,  9.87537503e-01, -2.17758760e-01,  8.26437324e-02,\n",
       "        1.53897002e-01, -7.26040006e-02, -1.44263683e-02, -1.23997256e-01,\n",
       "       -1.07008487e-01,  3.40928733e-02, -6.34614229e-02, -9.45577472e-02,\n",
       "        3.38668734e-01, -1.06250711e-01, -1.82056248e-01,  2.19470993e-01,\n",
       "       -1.58892125e-01,  6.11282513e-02,  1.33511633e-01,  5.97183742e-02,\n",
       "        1.34243131e-01,  1.33611500e-01, -1.02997571e-01, -1.49885744e-01,\n",
       "       -3.75362486e-02, -3.38061228e-02, -8.67414996e-02, -3.63667533e-02,\n",
       "        2.00054139e-01,  1.42539874e-01, -2.84347497e-02, -3.69590893e-02,\n",
       "        5.21373786e-02,  1.01151876e-01, -1.56987518e-01, -5.21989912e-02,\n",
       "        7.85263702e-02, -1.46083742e-01,  1.93346858e-01,  5.95576242e-02,\n",
       "        7.23850057e-02, -2.59389758e-01,  1.34413004e-01,  7.50462525e-03,\n",
       "       -7.25413710e-02, -1.84976235e-01, -8.31674933e-02,  2.56522834e-01,\n",
       "        2.37665400e-01, -1.09140128e-01, -2.20628247e-01, -9.45482403e-02,\n",
       "        1.20142490e-01,  1.24727249e-01,  1.98758632e-01,  1.00869760e-01,\n",
       "        3.97463620e-01, -7.83928782e-02,  1.58539861e-01,  2.49957487e-01,\n",
       "        1.56446755e-01, -1.48974255e-01,  6.69443794e-03,  3.01568151e-01,\n",
       "       -1.01776123e-01,  2.45034602e-02, -1.33566618e-01,  7.46697485e-02,\n",
       "       -8.78643766e-02, -2.69623220e-01,  4.62175012e-01, -3.38303745e-01,\n",
       "        3.69368792e-01,  2.58879978e-02, -2.54947484e-01,  7.35668689e-02,\n",
       "       -7.20347464e-02,  3.44997421e-02,  1.20836355e-01,  3.17422561e-02,\n",
       "       -1.44364998e-01, -1.42358243e-01, -1.22212498e-02, -4.52990010e-02,\n",
       "       -9.79699939e-02,  3.37363742e-02,  2.01742128e-01, -3.00495159e-02,\n",
       "        3.08763266e-01, -5.32541215e-01,  9.57054198e-02, -1.22298256e-01,\n",
       "       -1.48828765e-02,  1.21574655e-01,  1.40957370e-01, -1.64075047e-01,\n",
       "        2.23221779e-01, -9.64641273e-02,  1.66115627e-01, -1.92157924e-03,\n",
       "        1.82838142e-01, -1.65231004e-01, -1.42526627e-01,  5.74606434e-02,\n",
       "        1.22914873e-01,  1.76875480e-03,  8.81765038e-02,  1.87290050e-02,\n",
       "        8.22950080e-02,  4.84253764e-02, -2.97436304e-02, -2.92046875e-01,\n",
       "        3.00799347e-02,  1.42249838e-03,  1.20288871e-01, -1.14404991e-01,\n",
       "       -1.59445375e-01,  1.26734495e-01,  1.55667871e-01, -9.73373652e-02,\n",
       "       -1.01271629e-01, -2.95396112e-02, -2.44890004e-01, -3.06232497e-02,\n",
       "       -1.97953761e+00,  1.87205374e-01,  1.13133624e-01,  2.01669652e-02,\n",
       "       -8.06799997e-03, -1.40238374e-01, -1.20282128e-01,  1.79562032e-01,\n",
       "       -9.74632502e-02,  1.00875124e-01,  1.45785511e-01,  1.76990122e-01,\n",
       "       -3.07492521e-02,  1.13516198e-02, -2.39274837e-03, -3.96662503e-02,\n",
       "        4.53031324e-02, -1.69789493e-01,  1.98912621e-03, -1.00963503e-01,\n",
       "       -1.29809886e-01,  4.33959961e-02, -6.65737242e-02, -1.50277503e-02,\n",
       "        3.69635075e-02, -8.15868676e-02,  7.79512525e-02, -5.17779998e-02,\n",
       "        1.64786756e-01, -4.73408699e-02, -3.03086877e-01, -1.60377562e-01,\n",
       "        8.37823749e-02, -1.10526994e-01, -5.32537280e-03,  1.96102232e-01,\n",
       "       -1.35189742e-01,  1.28403991e-01,  8.07201266e-02,  9.93227512e-02,\n",
       "        8.68924782e-02, -1.31790023e-02, -2.70041257e-01, -2.38070488e-02,\n",
       "        1.29083749e-02, -4.94102463e-02, -5.26146218e-02, -1.63976118e-01,\n",
       "       -6.66964874e-02,  2.75137369e-03, -1.89374574e-03,  2.36598738e-02,\n",
       "       -1.55394748e-01, -2.47823335e-02,  1.06582761e-01,  7.22887274e-03,\n",
       "       -2.34408714e-02, -1.53124511e-01,  2.15303898e-01,  2.85619140e-01,\n",
       "       -3.49826291e-02, -1.25477880e-01, -1.25962883e-01, -6.75096214e-02,\n",
       "        1.12427585e-02,  9.74357501e-02,  7.03207478e-02, -3.36638689e-02,\n",
       "        3.65628675e-02, -2.88403761e-02, -7.33493790e-02, -3.26802492e-01,\n",
       "       -7.79427588e-02, -2.14966118e-01,  1.22137383e-01, -1.31241620e-01,\n",
       "       -3.00114341e-02,  1.37939602e-01, -4.13977504e-01, -2.00425118e-01,\n",
       "        6.78829998e-02,  3.83092687e-02, -1.20091617e-01, -3.94830629e-02,\n",
       "        1.30023003e-01,  4.98500373e-03, -7.97624663e-02,  1.25589699e-01,\n",
       "       -6.06388748e-02, -1.65745854e-01, -1.46711886e-01, -5.30836321e-02,\n",
       "        3.04589391e-01,  1.16511002e-01, -1.02951251e-01,  1.10189252e-01,\n",
       "        1.48081124e-01, -2.67217249e-01, -1.58380121e-01,  6.22451901e-02,\n",
       "        1.65610880e-01, -6.05283752e-02, -1.06260022e-02,  1.73764974e-02,\n",
       "        8.22778642e-02, -3.10866237e-01,  3.22754979e-02, -1.15263879e-01,\n",
       "       -1.85358122e-01,  4.24351245e-01,  3.68424989e-02, -1.82555482e-01,\n",
       "       -9.14796144e-02, -4.40126285e-02, -5.16853854e-03,  2.15577126e-01,\n",
       "       -1.62081227e-01,  7.56288692e-02,  2.16057390e-01, -1.13454973e-02,\n",
       "        8.92387331e-03, -2.87037715e-03,  1.25723675e-01,  8.21517967e-03,\n",
       "        8.94184932e-02,  1.07885495e-01, -1.38549462e-01,  1.68148637e-01,\n",
       "        3.01906228e-01,  8.90617520e-02, -4.51543778e-02, -1.81071199e-02,\n",
       "       -2.09941000e-01, -1.31799489e-01, -1.01698503e-01,  9.58862249e-03,\n",
       "        4.82682474e-02, -6.88981116e-02, -1.66022573e-02,  1.69162482e-01,\n",
       "        1.91175006e-02,  4.03608754e-02,  3.78501825e-02, -1.28138870e-01,\n",
       "       -3.80988792e-02, -9.33294594e-02, -1.90524980e-02, -9.49081257e-02,\n",
       "        6.32008761e-02, -2.29697004e-02, -1.70014381e-01,  6.84079528e-02,\n",
       "       -7.73837492e-02, -1.33924499e-01,  2.41113126e-01,  4.39511202e-02,\n",
       "       -1.90836132e-01, -7.63448775e-02,  1.54402509e-01,  1.04833215e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vector of the document as a whole:\n",
    "test_doc.vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confirm behavior on small subset of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# return lowercase lemmas of alphabetical\n",
    "def to_lc_lemmas(s):\n",
    "    \n",
    "    return [i.lemma_.lower() for i in s if doc_check(i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiny_df = X_train[0:2].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 39 ms, sys: 3.09 ms, total: 42.1 ms\n",
      "Wall time: 41.3 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "27301     (', Meša, Selimović, I, 'm, not, opposing, suc...\n",
       "141668    (', September, 2008, (, UTC, ), Talking, about...\n",
       "Name: docs, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# create docs from text\n",
    "tiny_df['docs'] = tiny_df['comment_text'].apply(nlp)\n",
    "tiny_df['docs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.21 ms, sys: 35 µs, total: 1.25 ms\n",
      "Wall time: 1.22 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "27301     [meša, selimović, oppose, formulation, instead...\n",
       "141668    [september, utc, talk, victimize, release, imp...\n",
       "Name: lemmas, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# keep subset of lc lemmas to reduce dimensions\n",
    "tiny_df['lemmas'] = tiny_df['docs'].apply(to_lc_lemmas)\n",
    "tiny_df['lemmas']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc Column\n",
    "\n",
    "This one will take the longest to process, but the docs must be created before the other features can be pulled from it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 4.05 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nCPU times: user 3min 17s, sys: 12.5 s, total: 3min 30s\\nWall time: 3min 32s\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "'''\n",
    "CPU times: user 3min 17s, sys: 12.5 s, total: 3min 30s\n",
    "Wall time: 3min 32s\n",
    "'''\n",
    "# if already created, load the column from pickle file\n",
    "# X_train['docs'] = pd.read_pickle('../data/basic_df_split/X_train_docs_series.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 1min 51s, sys: 31min 39s, total: 1h 33min 31s\n",
      "Wall time: 36min 56s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "27301     (', Meša, Selimović, I, 'm, not, opposing, suc...\n",
       "141668    (', September, 2008, (, UTC, ), Talking, about...\n",
       "Name: docs, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# '''\n",
    "# CPU times: user 38min 19s, sys: 3min 42s, total: 42min 2s\n",
    "# Wall time: 43min 21s\n",
    "# '''\n",
    "\n",
    "# create docs from text\n",
    "X_train['docs'] = X_train['comment_text'].apply(nlp)\n",
    "X_train['docs'].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['comment_text', 'uppercase_proportion', 'docs'], dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmas Column\n",
    "\n",
    "- text rendered to lemmas  \n",
    "- pronouns removed\n",
    "- preserve only alphabetical entities\n",
    "- remove stopwords in spaCy's default stopwords set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.58 s, sys: 133 ms, total: 8.72 s\n",
      "Wall time: 8.72 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "27301     [meša, selimović, oppose, formulation, instead...\n",
       "141668    [september, utc, talk, victimize, release, imp...\n",
       "Name: lemmas, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "'''\n",
    "CPU times: user 12.8 s, sys: 1.54 s, total: 14.3 s\n",
    "Wall time: 14.9 s\n",
    "'''\n",
    "\n",
    "# keep subset of lc lemmas to reduce dimensions\n",
    "X_train['lemmas'] = X_train['docs'].apply(to_lc_lemmas)\n",
    "X_train['lemmas'].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc Vector Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 3s, sys: 262 ms, total: 1min 4s\n",
      "Wall time: 1min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "'''\n",
    "CPU times: user 56.3 s, sys: 4.04 s, total: 1min\n",
    "Wall time: 1min 6s\n",
    "'''\n",
    "\n",
    "X_train['doc_vectors'] = X_train['docs'].apply(lambda x: x.vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of word vectors Column\n",
    "\n",
    "We will reduce the number of vectors by limiting our selection to those vectors representing lemmas that conform to our previous parameters and also have a non-zero vector.\n",
    "\n",
    "Resource:\n",
    "- [Getting Vector for Lemma](https://github.com/explosion/spaCy/issues/956) \n",
    "    - This was especially helpful for correctly formatting the lambda function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27301     [[0.12798, -0.43185, 0.034991, 0.27789, -0.061...\n",
       "141668    [[-0.02074, 0.42632, 0.59367, -0.090906, -0.08...\n",
       "Name: docs, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiny_doc_sample = X_train['docs'].head(2)\n",
    "\n",
    "# for doc in tiny_doc_sample:\n",
    "#     print(doc.vector)\n",
    "#     for tok in doc:\n",
    "#         if doc_check(tok) and tok.has_vector:\n",
    "#             print(tok.text, tok.has_vector, tok.vector_norm)\n",
    "\n",
    "# try with samll subset\n",
    "tiny_doc_sample.apply(lambda doc: [nlp.vocab[tok.lemma].vector for tok in doc if doc_check(tok) and tok.has_vector])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.3 s, sys: 183 ms, total: 15.5 s\n",
      "Wall time: 15.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "'''\n",
    "CPU times: user 17.4 s, sys: 396 ms, total: 17.8 s\n",
    "Wall time: 18 s\n",
    "\n",
    "'''\n",
    "X_train['tok_vectors'] = X_train['docs'].apply(lambda doc: [nlp.vocab[tok.lemma].vector for tok in doc if doc_check(tok) and tok.has_vector])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['comment_text', 'uppercase_proportion', 'docs', 'lemmas', 'doc_vectors',\n",
       "       'tok_vectors'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preserve Doc column separately\n",
    "\n",
    "As the doc column is quite large, we'll preserve it seperately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 45.3 s, sys: 23.2 s, total: 1min 8s\n",
      "Wall time: 1min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "'''\n",
    "CPU times: user 48.3 s, sys: 30.3 s, total: 1min 18s\n",
    "Wall time: 1min 55s\n",
    "'''\n",
    "\n",
    "X_train['docs'].to_pickle('../data/basic_df_split/X_train_docs_series.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "print(\"hi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# left off here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_config.cfg       \u001b[1m\u001b[36mspacy_2\u001b[m\u001b[m               \u001b[1m\u001b[36mspacy_multi_cat_model\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "# ls ../models\n",
    "# ! mkdir ../models/spacy_2\n",
    "! ls ../models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_config.cfg       \u001b[1m\u001b[36mspacy_2\u001b[m\u001b[m               \u001b[1m\u001b[36mspacy_multi_cat_model\u001b[m\u001b[m\n",
      "base_config.cfg       \u001b[1m\u001b[36mspacy_2\u001b[m\u001b[m               \u001b[1m\u001b[36mspacy_multi_cat_model\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "! ls ../models\n",
    "nlp.to_disk(\"../models/spacy_2/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preserve X_train with new columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 14s, sys: 1min 12s, total: 2min 27s\n",
      "Wall time: 4min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train.to_pickle('../data/basic_df_split/X_train_2-1.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iaWoMJGfVwUB",
    "tags": []
   },
   "source": [
    "# Toxic Text\n",
    "\n",
    "\n",
    "Detecting Insults in Social Commentary\n",
    "\n",
    "Data from Wikipedia \n",
    "\n",
    "Data Source:\n",
    "https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/data\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
