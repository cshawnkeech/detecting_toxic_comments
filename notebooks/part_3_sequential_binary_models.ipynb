{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting and Classifying Toxic Comments\n",
    "# Part 3-1: Sequential Binary Classifiers\n",
    "\n",
    "It may be possible to employ sequential binary models in order to get better results with rarer cases.\n",
    "\n",
    "If we first classify Toxic and Not Toxic, we could further process only the Toxic results against models that had been trained only to recognise sub-classes of toxic models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spaCy Setup and Imports\n",
    "\n",
    "This time, we'll only use spaCy for data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "from spacy.lang.en import English\n",
    "spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "from spacy.tokens import Doc\n",
    "import en_core_web_lg\n",
    "nlp = en_core_web_lg.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Custom Functions\n",
    "\n",
    "I've created a few custom functions to assist in text preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# add src folder to path\n",
    "sys.path.insert(1, '../src')\n",
    "\n",
    "# from text_prep import tidy_series, uppercase_proportion_column\n",
    "from spacy_helper import doc_check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Train & Test Dataframes from Pickle File\n",
    "\n",
    "We've already done a stratified Train Test Split, and a little bit of very basic text processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basic_X_test.pkl  basic_X_train.pkl basic_y_test.pkl  basic_y_train.pkl\n"
     ]
    }
   ],
   "source": [
    "# ! ls ../data/basic_df_split/\n",
    "\n",
    "X_train = pd.read_pickle('../data/basic_df_split/basic_X_train.pkl')\n",
    "X_test = pd.read_pickle('../data/basic_df_split/basic_X_test.pkl')\n",
    "y_train = pd.read_pickle('../data/basic_df_split/basic_y_train.pkl')\n",
    "y_test= pd.read_pickle('../data/basic_df_split/basic_y_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 106912 entries, 27301 to 14596\n",
      "Data columns (total 2 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   comment_text          106912 non-null  object \n",
      " 1   uppercase_proportion  106897 non-null  float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 2.4+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(X_train.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 106912 entries, 27301 to 14596\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count   Dtype\n",
      "---  ------         --------------   -----\n",
      " 0   toxic          106912 non-null  int64\n",
      " 1   severe_toxic   106912 non-null  int64\n",
      " 2   obscene        106912 non-null  int64\n",
      " 3   threat         106912 non-null  int64\n",
      " 4   insult         106912 non-null  int64\n",
      " 5   identity_hate  106912 non-null  int64\n",
      "dtypes: int64(6)\n",
      "memory usage: 5.7 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(y_train.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1: Use spaCy for feature reduction\n",
    "\n",
    "We will utilize spaCy to reduce features to:\n",
    "- remove stopwords\n",
    "- remove punctuation\n",
    "- retain only lemmas\n",
    "- render all lemmas to lowercase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1a: testing process with subset of text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create test subset copy\n",
    "text_sub = X_train['comment_text'].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It was you who initiated this request and your colleague BlankVerse added me into the mix [here]. I'm sure you are aware that those IP checks are for Arbitration Committee issues only right? Simply to satify your curiousity does not qualify as a reason to invade my (or anyone else's) privacy. I left the same message on BlankVerse's talk page as well. Sincerely,\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_sub.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'spacy.tokens.doc.Doc'>\n"
     ]
    }
   ],
   "source": [
    "test_doc = nlp(text_sub.iloc[0])\n",
    "print(type(test_doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['initiate',\n",
       " 'request',\n",
       " 'colleague',\n",
       " 'blankverse',\n",
       " 'add',\n",
       " 'mix',\n",
       " 'sure',\n",
       " 'aware',\n",
       " 'ip',\n",
       " 'check',\n",
       " 'arbitration',\n",
       " 'committee',\n",
       " 'issue',\n",
       " 'right',\n",
       " 'simply',\n",
       " 'satify',\n",
       " 'curiousity',\n",
       " 'qualify',\n",
       " 'reason',\n",
       " 'invade',\n",
       " 'privacy',\n",
       " 'leave',\n",
       " 'message',\n",
       " 'blankverse',\n",
       " 'talk',\n",
       " 'page',\n",
       " 'sincerely']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmas_lc = [i.lemma_.lower() for i in test_doc if doc_check(i)]\n",
    "lemmas_lc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.13121418e-02,  1.48708686e-01, -2.18804672e-01,  2.12305575e-03,\n",
       "        6.60265684e-02,  4.28793095e-02, -2.85865436e-03, -2.22052231e-01,\n",
       "       -2.84318291e-02,  2.12891936e+00, -1.49136350e-01,  5.84894195e-02,\n",
       "        7.73073360e-02, -6.52949363e-02, -9.85272750e-02, -4.07859012e-02,\n",
       "       -8.40210617e-02,  1.03252184e+00, -2.14530215e-01,  2.21992079e-02,\n",
       "       -4.42361413e-03, -2.86064092e-02, -3.81505936e-02, -2.50708833e-02,\n",
       "        1.76838264e-02,  2.72275545e-02, -3.40951905e-02, -9.39358771e-02,\n",
       "        3.59738655e-02, -1.24521852e-01, -1.76976230e-02,  1.41400397e-01,\n",
       "       -7.65471235e-02,  6.01183064e-02,  1.30067756e-02, -8.55363235e-02,\n",
       "        1.19203480e-03,  5.07408418e-02, -8.37911591e-02, -7.08299801e-02,\n",
       "       -2.41037142e-02,  2.25989874e-02,  1.92791447e-02, -4.06242758e-02,\n",
       "       -2.73231473e-02,  6.00152463e-02, -1.01027787e-01,  1.79745089e-02,\n",
       "        1.89492758e-02,  2.74333346e-04, -8.50247666e-02,  2.67418311e-03,\n",
       "       -4.88690697e-02, -5.85913099e-02,  6.50208890e-02,  7.01800361e-03,\n",
       "       -7.00307116e-02, -1.07088625e-01, -1.29937464e-02, -7.43899494e-02,\n",
       "       -6.63380325e-02, -4.44361977e-02, -3.56918722e-02,  1.60474211e-01,\n",
       "        7.60776550e-02, -5.58031164e-02, -4.76960130e-02,  4.64213379e-02,\n",
       "        6.17821282e-03,  7.24100620e-02,  1.18043669e-01,  8.86769742e-02,\n",
       "        2.47013927e-01, -4.69531268e-02,  1.21046521e-01,  8.50183293e-02,\n",
       "        1.05242133e-01, -8.87895301e-02, -7.27599934e-02,  2.11401120e-01,\n",
       "       -1.00666648e-02,  4.67798337e-02, -2.04879805e-01, -7.99172092e-03,\n",
       "        5.53928390e-02, -1.46200061e-01,  6.06064722e-02, -2.61610568e-01,\n",
       "        2.82294214e-01, -6.19442854e-03, -1.29388303e-01,  2.55235843e-02,\n",
       "        3.51157784e-02,  3.77361216e-02,  1.40594721e-01, -3.79751287e-02,\n",
       "       -7.70166963e-02, -1.08344741e-01, -4.05274332e-03,  6.25316948e-02,\n",
       "       -2.24415958e-02,  2.88860612e-02,  8.04731902e-03, -4.12248336e-02,\n",
       "        1.16611280e-01, -6.03812516e-01,  1.09569743e-01,  5.03417151e-03,\n",
       "       -1.22244339e-02,  4.89282049e-02,  4.25334871e-02, -1.31380215e-01,\n",
       "        1.50106236e-01, -1.49341933e-02,  3.04542221e-02, -6.29110560e-02,\n",
       "       -1.57823160e-04, -7.95604810e-02, -4.01847251e-02, -2.92122103e-02,\n",
       "        8.83699432e-02, -8.70804712e-02,  1.28508592e-03, -1.39370011e-02,\n",
       "        9.83978286e-02,  7.03382194e-02, -3.07660475e-02, -1.01160437e-01,\n",
       "        3.56689803e-02,  1.69579387e-02,  1.20918723e-02, -2.35115811e-02,\n",
       "       -1.50745913e-01, -7.50157633e-04,  4.19236571e-02,  3.07257492e-02,\n",
       "        1.78708192e-02,  1.03358217e-02, -1.62448213e-02, -2.55416129e-02,\n",
       "       -1.08038986e+00,  8.53248611e-02,  7.94157758e-02,  3.01274043e-02,\n",
       "       -1.80404983e-04, -6.27451837e-02, -6.92964271e-02,  2.69897357e-02,\n",
       "       -9.76523459e-02, -6.14661202e-02, -1.03860646e-02,  8.05100128e-02,\n",
       "        6.86452612e-02, -3.44998725e-02, -2.14331690e-02,  3.38549949e-02,\n",
       "       -7.90065750e-02, -1.46314083e-02, -1.19118961e-02, -1.60908867e-02,\n",
       "       -6.20514937e-02,  2.32335180e-02, -4.59891036e-02, -9.08443183e-02,\n",
       "       -1.22874714e-01, -1.56242043e-01,  5.72707504e-02, -4.01789472e-02,\n",
       "        1.41528919e-01, -2.39754003e-02, -3.51629667e-02, -5.27175926e-02,\n",
       "        1.28579065e-01, -1.12487808e-01, -3.16078551e-02,  7.62792528e-02,\n",
       "        1.24285007e-02, -1.15013709e-02, -1.24061191e-02,  5.45613356e-02,\n",
       "        3.11480332e-02, -5.34063913e-02, -7.47817233e-02, -9.31013227e-02,\n",
       "       -2.24554166e-02,  7.84163829e-03, -9.41701382e-02, -4.49088663e-02,\n",
       "        1.37642706e-02,  2.58966740e-02,  1.39349652e-02,  8.22671223e-03,\n",
       "       -1.19311102e-01,  1.24720356e-03,  8.63279998e-02,  1.04998924e-01,\n",
       "       -7.02655315e-02, -1.10941760e-01,  8.58340934e-02,  2.48547181e-01,\n",
       "       -3.61246094e-02, -8.46709386e-02, -1.21436872e-01, -4.01071645e-03,\n",
       "        1.81998238e-01,  5.18872254e-02,  7.36985877e-02,  1.31517963e-03,\n",
       "        3.89787443e-02,  2.05971859e-02,  1.81533891e-04, -9.66268703e-02,\n",
       "       -4.71530249e-03, -1.33162156e-01,  4.85989228e-02,  1.26481771e-01,\n",
       "       -5.99890277e-02,  1.47431931e-02, -3.36971462e-01,  4.92825359e-03,\n",
       "       -1.06203798e-02,  3.49189201e-03, -5.45072295e-02,  4.59004305e-02,\n",
       "        7.27001801e-02, -4.02193293e-02,  3.10115851e-02,  7.04912022e-02,\n",
       "       -2.11288016e-02, -6.54286891e-02, -1.60614803e-01, -1.09502636e-02,\n",
       "        5.36298566e-02,  1.12804018e-01, -5.81175797e-02, -8.77467319e-02,\n",
       "       -2.81145833e-02, -1.22208402e-01, -3.64923403e-02,  8.12514722e-02,\n",
       "        7.37175792e-02,  9.12751108e-02,  2.13936623e-02,  3.56952175e-02,\n",
       "        1.19423673e-01, -2.26637065e-01, -5.98978475e-02, -6.47461414e-02,\n",
       "       -1.29315764e-01,  7.71508068e-02,  8.89577344e-02, -6.16550259e-02,\n",
       "       -8.48998725e-02, -9.79212020e-03,  5.14389127e-02,  1.80067062e-01,\n",
       "        3.44856344e-02, -1.28220454e-01,  4.64927666e-02,  5.40181175e-02,\n",
       "        3.54223251e-02,  1.23538934e-01,  3.69764306e-02,  2.04783827e-02,\n",
       "        4.65011112e-02, -3.73366065e-02, -2.42103189e-02,  6.14852831e-02,\n",
       "        4.59089905e-01, -7.13842874e-03,  1.13341138e-01,  1.37342196e-02,\n",
       "       -9.98865515e-02, -9.73372534e-02,  1.04613621e-02,  2.33711973e-02,\n",
       "        4.32290602e-03,  5.58791868e-02,  1.42400740e-02,  1.57154769e-01,\n",
       "        1.56842738e-01,  2.96420027e-02,  7.17431903e-02, -5.74244708e-02,\n",
       "       -6.91916943e-02, -7.31956810e-02,  9.91643518e-02,  2.77196552e-04,\n",
       "        1.26510873e-01, -2.61456203e-02, -1.47503316e-01,  2.78957263e-02,\n",
       "       -2.11118739e-02, -3.32550220e-02,  8.37308690e-02, -4.81226705e-02,\n",
       "       -4.70861383e-02, -9.02148485e-02,  6.75692931e-02,  1.09869145e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vector of the document as a whole:\n",
    "test_doc.vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confirm behavior on small subset of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# return lowercase lemmas of alphabetical\n",
    "def to_lc_lemmas(s):\n",
    "    \n",
    "    return [i.lemma_.lower() for i in s if doc_check(i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiny_df = X_train[0:2].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# create docs from text\n",
    "tiny_df['docs'] = tiny_df['comment_text'].apply(nlp)\n",
    "tiny_df['docs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.08 ms, sys: 67 µs, total: 1.15 ms\n",
      "Wall time: 1.18 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "27301     [meša, selimović, oppose, formulation, instead...\n",
       "141668    [september, utc, talk, victimize, release, imp...\n",
       "Name: lemmas, dtype: object"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# keep subset of lc lemmas to reduce dimensions\n",
    "tiny_df['lemmas'] = tiny_df['docs'].apply(to_lc_lemmas)\n",
    "tiny_df['lemmas']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# left off here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc Column\n",
    "\n",
    "This one will take the longest to process, but the docs must be created before the other features can be pulled from it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 38min 19s, sys: 3min 42s, total: 42min 2s\n",
      "Wall time: 43min 21s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "27301     (', Meša, Selimović, I, 'm, not, opposing, suc...\n",
       "141668    (', September, 2008, (, UTC, ), Talking, about...\n",
       "Name: docs, dtype: object"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "'''\n",
    "CPU times: user 38min 19s, sys: 3min 42s, total: 42min 2s\n",
    "Wall time: 43min 21s\n",
    "'''\n",
    "\n",
    "# create docs from text\n",
    "X_train['docs'] = X_train['comment_text'].apply(nlp)\n",
    "X_train['docs'].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmas Column\n",
    "\n",
    "- text rendered to lemmas  \n",
    "- pronouns removed\n",
    "- preserve only alphabetical entities\n",
    "- remove stopwords in spaCy's default stopwords set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.8 s, sys: 1.54 s, total: 14.3 s\n",
      "Wall time: 14.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "27301     [meša, selimović, oppose, formulation, instead...\n",
       "141668    [september, utc, talk, victimize, release, imp...\n",
       "Name: lemmas, dtype: object"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "'''\n",
    "CPU times: user 12.8 s, sys: 1.54 s, total: 14.3 s\n",
    "Wall time: 14.9 s\n",
    "'''\n",
    "\n",
    "# keep subset of lc lemmas to reduce dimensions\n",
    "X_train['lemmas'] = X_train['docs'].apply(to_lc_lemmas)\n",
    "X_train['lemmas'].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc Vector Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 56.3 s, sys: 4.04 s, total: 1min\n",
      "Wall time: 1min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "'''\n",
    "CPU times: user 56.3 s, sys: 4.04 s, total: 1min\n",
    "Wall time: 1min 6s\n",
    "'''\n",
    "\n",
    "X_train['doc_vectors'] = X_train['docs'].apply(lambda x: x.vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of word vectors\n",
    "\n",
    "We will reduce the number of vectors by limiting our selection to those vectors representing lemmas that conform to our previous parameters and also have a non-zero vector.\n",
    "\n",
    "Resource:\n",
    "- [Getting Vector for Lemma](https://github.com/explosion/spaCy/issues/956) \n",
    "    - This was especially helpful for correctly formatting the lambda function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27301     [[0.12798, -0.43185, 0.034991, 0.27789, -0.061...\n",
       "141668    [[-0.02074, 0.42632, 0.59367, -0.090906, -0.08...\n",
       "Name: docs, dtype: object"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiny_doc_sample = X_train['docs'].head(2)\n",
    "\n",
    "# for doc in tiny_doc_sample:\n",
    "#     print(doc.vector)\n",
    "#     for tok in doc:\n",
    "#         if doc_check(tok) and tok.has_vector:\n",
    "#             print(tok.text, tok.has_vector, tok.vector_norm)\n",
    "\n",
    "# try with samll subset\n",
    "tiny_doc_sample.apply(lambda doc: [nlp.vocab[tok.lemma].vector for tok in doc if doc_check(tok) and tok.has_vector])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.4 s, sys: 396 ms, total: 17.8 s\n",
      "Wall time: 18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "'''\n",
    "CPU times: user 17.4 s, sys: 396 ms, total: 17.8 s\n",
    "Wall time: 18 s\n",
    "\n",
    "'''\n",
    "X_train['tok_vectors'] = X_train['docs'].apply(lambda doc: [nlp.vocab[tok.lemma].vector for tok in doc if doc_check(tok) and tok.has_vector])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['tok_vectors'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preserve Doc column separately\n",
    "\n",
    "As the doc column is quite large, we'll preserve it seperately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 48.3 s, sys: 30.3 s, total: 1min 18s\n",
      "Wall time: 1min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "'''\n",
    "CPU times: user 48.3 s, sys: 30.3 s, total: 1min 18s\n",
    "Wall time: 1min 55s\n",
    "'''\n",
    "\n",
    "X_train[['docs']].to_pickle('../data/basic_df_split/X_train_docs_series.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iaWoMJGfVwUB",
    "tags": []
   },
   "source": [
    "# Toxic Text\n",
    "\n",
    "\n",
    "Detecting Insults in Social Commentary\n",
    "\n",
    "Data from Wikipedia \n",
    "\n",
    "Data Source:\n",
    "https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/data\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
