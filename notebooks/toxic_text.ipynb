{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"toxic_text.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyOCF+j+08tL5QgwPVB141nM"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"iaWoMJGfVwUB"},"source":["# Toxic Text\n","\n","\n","Detecting Insults in Social Commentary\n","\n","Data from Wikipedia "]},{"cell_type":"markdown","metadata":{"id":"sMY7K_Yx9NVJ"},"source":["# Resources & Articles\n","\n","Resources:\n","- [Detecting Insults in Social Commentary Dataset On Kaggle](https://www.kaggle.com/c/detecting-insults-in-social-commentary/data) \n","- [Cleaned Toxic Comments on Kaggle](https://www.kaggle.com/fizzbuzz/cleaned-toxic-comments)  \n","- [Insult Sets](https://www.kaggle.com/rogier2012/insult-sets)  \n","- [Wikipedia Talk Labels: Personal Attacks](https://datasetsearch.research.google.com/search?query=stalking%20text&docid=L2cvMTFqbnl5cWw0Xw%3D%3D) \n","    -  [At Kaggle](https://datasetsearch.research.google.com/search?query=stalking%20text&docid=L2cvMTFqbnl5cWw0Xw%3D%3D)  \n","- [Toxic Dataset](https://www.kaggle.com/ra2041/toxic-dataset)  \n","- [Dataset for Mean Birds: Detecting Agression and Bullying on Twitter](https://zenodo.org/record/1184178) \n","\n","Articles: \n","- [NLP AND MACHINE LEARNING TECHNIQUES TO DETECT\n","ONLINE HARASSMENT...(has links to datasets)](https://dalspace.library.dal.ca/handle/10222/76331) \n","- [Detecting Cyberbullying...](http://www.ijetsr.com/images/short_pdf/1517199597_1428-1435-oucip915_ijetsr.pdf) \n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"kivyT28oYMWZ"},"source":["# Setup\n","\n","We'll mount our Google Drive and import any necessary Python libraries."]},{"cell_type":"markdown","metadata":{"id":"2qK_rIp9YYD4"},"source":["## Mount Google Drive\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gvgsrbNQYIzZ","executionInfo":{"status":"ok","timestamp":1616376261699,"user_tz":300,"elapsed":324,"user":{"displayName":"Shawn Keech","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicFJvHjGKSkP2elE1kc5WTSumC2FDDidD75Ssv0w=s64","userId":"08670766559094446918"}},"outputId":"870642f4-1eee-451c-964d-37865419de6f"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zS90Y8MyYyVe","executionInfo":{"status":"ok","timestamp":1616376262082,"user_tz":300,"elapsed":697,"user":{"displayName":"Shawn Keech","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicFJvHjGKSkP2elE1kc5WTSumC2FDDidD75Ssv0w=s64","userId":"08670766559094446918"}},"outputId":"c349b7e1-fcc1-4489-cb9b-406a59b6c77d"},"source":["# ! pwd\n","# /content\n","\n","! ls /content/gdrive/MyDrive/'Colab Notebooks'/capstone_exploration/data"],"execution_count":2,"outputs":[{"output_type":"stream","text":["ship_detection_data  toxic_comment_data\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"uqBZisuwa0X7"},"source":["## Kaggle Setup & Imports\n","\n","We'll be using at least one Kaggle dataset.\n","\n","Resources: \n","\n","- [Downloading Datasets directly into Google Drive](https://towardsdatascience.com/downloading-datasets-into-google-drive-via-google-colab-bcb1b30b0166)  \n"]},{"cell_type":"code","metadata":{"id":"hUnUWyqKa0zz","executionInfo":{"status":"ok","timestamp":1616376262083,"user_tz":300,"elapsed":695,"user":{"displayName":"Shawn Keech","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicFJvHjGKSkP2elE1kc5WTSumC2FDDidD75Ssv0w=s64","userId":"08670766559094446918"}}},"source":["# '''\n","# This code has been commented out as\n","# it is only necessary to run this once with your credentials.\n","\n","# credentials, however, seem to be stored on the local machine\n","# '''\n","\n","# from google.colab import files\n","# files.upload() #this will prompt you to update the json\n","\n","# !pip install -q kaggle\n","# !mkdir -p ~/.kaggle\n","# !cp kaggle.json ~/.kaggle/\n","# !ls ~/.kaggle\n","# !chmod 600 /root/.kaggle/kaggle.json  # set permission"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"hMo9xs_eQ_nr","executionInfo":{"status":"ok","timestamp":1616376262084,"user_tz":300,"elapsed":693,"user":{"displayName":"Shawn Keech","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicFJvHjGKSkP2elE1kc5WTSumC2FDDidD75Ssv0w=s64","userId":"08670766559094446918"}}},"source":["# ! ls gdrive/MyDrive/'Colab Notebooks'/capstone_exploration/data/toxic_comment_data"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"N-nZKv4PM-vd","executionInfo":{"status":"ok","timestamp":1616376262084,"user_tz":300,"elapsed":691,"user":{"displayName":"Shawn Keech","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicFJvHjGKSkP2elE1kc5WTSumC2FDDidD75Ssv0w=s64","userId":"08670766559094446918"}}},"source":["# ! pwd\n","\n","# ! ls gdrive/MyDrive/'Colab Notebooks'/capstone_exploration/data"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"CQ4bXWwkJbWD","executionInfo":{"status":"ok","timestamp":1616376262085,"user_tz":300,"elapsed":690,"user":{"displayName":"Shawn Keech","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicFJvHjGKSkP2elE1kc5WTSumC2FDDidD75Ssv0w=s64","userId":"08670766559094446918"}}},"source":["# ! kaggle competitions list -s jigsaw-toxic-comment-classification-challenge\n","\n","# ! kaggle competitions download -c jigsaw-toxic-comment-classification-challenge -p /content/gdrive/MyDrive/Colab\\ Notebooks/capstone_exploration/data"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xTRgdYMCHaHD"},"source":["## spaCy Setup & Imports"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"59WyH44vAItf","executionInfo":{"status":"ok","timestamp":1616376284471,"user_tz":300,"elapsed":23067,"user":{"displayName":"Shawn Keech","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicFJvHjGKSkP2elE1kc5WTSumC2FDDidD75Ssv0w=s64","userId":"08670766559094446918"}},"outputId":"781ffc29-4ec9-4a24-874a-f59557d6608d"},"source":["# spaCy Setup & Imports\n","import spacy\n","from spacy.lang.en import English\n","\n","# update install to > version 3\n","! pip install -U spacy\n","\n","spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS\n","! python -m spacy download en_core_web_lg"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Requirement already up-to-date: spacy in /usr/local/lib/python3.7/dist-packages (3.0.5)\n","Requirement already satisfied, skipping upgrade: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from spacy) (3.7.2)\n","Requirement already satisfied, skipping upgrade: typer<0.4.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.3.2)\n","Requirement already satisfied, skipping upgrade: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n","Requirement already satisfied, skipping upgrade: catalogue<2.1.0,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.1)\n","Requirement already satisfied, skipping upgrade: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.0)\n","Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (54.1.2)\n","Requirement already satisfied, skipping upgrade: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.19.5)\n","Requirement already satisfied, skipping upgrade: srsly<3.0.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.4.0)\n","Requirement already satisfied, skipping upgrade: pydantic<1.8.0,>=1.7.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.7.3)\n","Requirement already satisfied, skipping upgrade: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.8.2)\n","Requirement already satisfied, skipping upgrade: typing-extensions<4.0.0.0,>=3.7.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from spacy) (3.7.4.3)\n","Requirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.5)\n","Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n","Requirement already satisfied, skipping upgrade: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (20.9)\n","Requirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.41.1)\n","Requirement already satisfied, skipping upgrade: spacy-legacy<3.1.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.1)\n","Requirement already satisfied, skipping upgrade: thinc<8.1.0,>=8.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (8.0.2)\n","Requirement already satisfied, skipping upgrade: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.11.3)\n","Requirement already satisfied, skipping upgrade: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.5)\n","Requirement already satisfied, skipping upgrade: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n","Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->spacy) (3.4.1)\n","Requirement already satisfied, skipping upgrade: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.0->spacy) (7.1.2)\n","Requirement already satisfied, skipping upgrade: smart-open<4.0.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy) (3.0.0)\n","Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy) (2.4.7)\n","Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy) (1.1.1)\n","Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n","Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n","Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n","Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.12.5)\n","2021-03-22 01:24:37.630099: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n","Requirement already satisfied: en-core-web-lg==3.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.0.0/en_core_web_lg-3.0.0-py3-none-any.whl#egg=en_core_web_lg==3.0.0 in /usr/local/lib/python3.7/dist-packages (3.0.0)\n","Requirement already satisfied: spacy<3.1.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from en-core-web-lg==3.0.0) (3.0.5)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (2.4.0)\n","Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (0.4.0)\n","Requirement already satisfied: thinc<8.1.0,>=8.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (8.0.2)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (3.0.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (2.11.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (54.1.2)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (4.41.1)\n","Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (0.8.2)\n","Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (1.7.3)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (1.19.5)\n","Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (3.7.4.3)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (2.0.5)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (2.23.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (20.9)\n","Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (0.4.1)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (2.0.1)\n","Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (3.7.2)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (1.0.5)\n","Requirement already satisfied: typer<0.4.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (0.3.2)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (3.0.1)\n","Requirement already satisfied: smart-open<4.0.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (3.0.0)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (1.1.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (2020.12.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (3.0.4)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (2.4.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (3.4.1)\n","Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.0->spacy<3.1.0,>=3.0.0->en-core-web-lg==3.0.0) (7.1.2)\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('en_core_web_lg')\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"XDRcsr5AZfQb"},"source":["## Python Library Imports\n","\n","\n","Resources:\n","- [pool]()"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mQY7o6xDZhTe","executionInfo":{"status":"ok","timestamp":1616376286409,"user_tz":300,"elapsed":24997,"user":{"displayName":"Shawn Keech","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicFJvHjGKSkP2elE1kc5WTSumC2FDDidD75Ssv0w=s64","userId":"08670766559094446918"}},"outputId":"73aee6d3-7edd-437f-eab4-36c67320b567"},"source":["import pandas as pd\n","import numpy as np\n","\n","from collections import Counter\n","import re\n","\n","# nltk imports\n","import nltk\n","nltk.download('averaged_perceptron_tagger')\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","from nltk.corpus import stopwords\n","\n","\n","# scikit learn imports\n","from sklearn.model_selection import train_test_split\n","\n","%load_ext autoreload\n","%autoreload 2"],"execution_count":8,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"sLj78JbffsQ8"},"source":["## Import Data to DataFrame"]},{"cell_type":"code","metadata":{"id":"UeyUW0XJRVGY","executionInfo":{"status":"ok","timestamp":1616376288364,"user_tz":300,"elapsed":26950,"user":{"displayName":"Shawn Keech","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicFJvHjGKSkP2elE1kc5WTSumC2FDDidD75Ssv0w=s64","userId":"08670766559094446918"}}},"source":["path = \"gdrive/MyDrive/Colab Notebooks/capstone_exploration/data/toxic_comment_data/train.csv\"\n","\n","toxic_df = pd.read_csv(path)"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j2pbrgM5f0o6"},"source":["# Basic Exploration\n","\n","Texts in the dataset are labeled by human users as either **Toxic** or **Not Toxic**. \n","\n","Toxic comments can be further categorized as displaying any combination of five subcategories. Toxic comments can belong to any of the subcategories, multiple subcategories, or no further subcategories.\n","\n","Subcategories:\n","- Severely toxic\n","- Obscene\n","- Threat\n","- Insult\n","- Identity hate\n","\n","### Category Summary\n","\n","| Category            \t| Totals \t|\n","|---------------------\t|-------:\t|\n","| Not Toxic         \t| 144277 \t|\n","| Toxic             \t|  15294 \t|\n","| Toxic Subcategories \t|        \t|\n","| Severely toxic      \t|   1595 \t|\n","| Obscene             \t|   8449 \t|\n","| Threat              \t|    478 \t|\n","| Insult              \t|   7877 \t|\n","| Identity hate       \t|   1405 \t|\n","| Subcategories Total \t|  19804 \t|\n","\n","\n","### Proportions\n","\n","About 10% of the comments in the dataset are considered Toxic.\n","\n","```\n","Proportion of Not Toxic Comments in Dataset: 0.9041555169799024\n","Proportion of Toxic Comments in Dataset: 0.09584448302009764\n","```\n","\n","\n","Resources:\n","- [Table Generator](https://www.tablesgenerator.com/markdown_tables#)  "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"453r8KHXRsZh","executionInfo":{"status":"ok","timestamp":1616376288366,"user_tz":300,"elapsed":26944,"user":{"displayName":"Shawn Keech","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicFJvHjGKSkP2elE1kc5WTSumC2FDDidD75Ssv0w=s64","userId":"08670766559094446918"}},"outputId":"899de06c-d6f1-44d5-a249-676f78ffd696"},"source":["# how many rows labeled as not toxic?\n","not_toxic_count = toxic_df[toxic_df['toxic']==0].shape[0]\n","print(f\"Rows labeled as Not Toxic: {not_toxic_count}\") # not toxic: (144277) \n","\n","# rows labeled toxic\n","toxic_count = toxic_df[toxic_df['toxic']==1].shape[0]\n","print(f\"Rows labeled as Toxic:      {toxic_count}\") # toxic: (15294)\n","print('\\n')\n","sub_toxic = toxic_df[['severe_toxic', 'obscene','threat','insult','identity_hate']].sum()\n","\n","print(sub_toxic, '\\n')\n","print(f\"total sub_toxic:            {sub_toxic.sum()}\")\n"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Rows labeled as Not Toxic: 144277\n","Rows labeled as Toxic:      15294\n","\n","\n","severe_toxic     1595\n","obscene          8449\n","threat            478\n","insult           7877\n","identity_hate    1405\n","dtype: int64 \n","\n","total sub_toxic:            19804\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7A-LuVRNnRfc","executionInfo":{"status":"ok","timestamp":1616376288367,"user_tz":300,"elapsed":26936,"user":{"displayName":"Shawn Keech","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicFJvHjGKSkP2elE1kc5WTSumC2FDDidD75Ssv0w=s64","userId":"08670766559094446918"}},"outputId":"9caf5744-63cd-4cbb-e413-0e23a9f72106"},"source":["# Proportions:\n","total_rows = toxic_df.shape[0] # 159571\n","\n","# Not Toxic Proportion\n","not_toxic_prop = not_toxic_count/total_rows # 0.9041555169799024\n","print(f\"Proportion of Not Toxic Comments in Dataset: {not_toxic_prop}\")\n","\n","# Toxic Proportion\n","toxic_prop = toxic_count/total_rows # 0.09584448302009764\n","print(f\"Proportion of Toxic Comments in Dataset: {toxic_prop}\")\n"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Proportion of Not Toxic Comments in Dataset: 0.9041555169799024\n","Proportion of Toxic Comments in Dataset: 0.09584448302009764\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"oxhq-7EOfpsB"},"source":["# Drop 'id' Column From Full Dataset\n","The id column is not really useful for our purposes, so we'll drop it from the dataframe"]},{"cell_type":"code","metadata":{"id":"EXnAvoBef08q","executionInfo":{"status":"ok","timestamp":1616376288367,"user_tz":300,"elapsed":26935,"user":{"displayName":"Shawn Keech","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicFJvHjGKSkP2elE1kc5WTSumC2FDDidD75Ssv0w=s64","userId":"08670766559094446918"}}},"source":["toxic_df.drop(columns='id', inplace=True)"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Gr3jPH3xfJkg"},"source":["# Basic Data Cleaning"]},{"cell_type":"markdown","metadata":{"id":"I1Md0mKVKwF9"},"source":["Cleaning Functions:\n","- convert interior quotes to all single quotes\n","- strip any extraneous whitespace\n","- strip any ip addresses\n"]},{"cell_type":"code","metadata":{"id":"-yt0qUU9aTpR","executionInfo":{"status":"ok","timestamp":1616376288495,"user_tz":300,"elapsed":27061,"user":{"displayName":"Shawn Keech","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicFJvHjGKSkP2elE1kc5WTSumC2FDDidD75Ssv0w=s64","userId":"08670766559094446918"}}},"source":["# Convert all interior quotes to single quotes\n","\n","def convert_interior_quotes(s):\n","    '''\n","    Arguments:\n","        s = Series of strings\n","            Takes a series of strings as an argument\n","            converts all interior quotes in a string to single quotes\n","    Returns: \n","        Series of strings with interior quotes\n","    '''\n","    quotes_pattern = '[\"]+'\n","    return s.str.replace(quotes_pattern, \"'\")\n","\n","def strip_ip(s):\n","    '''\n","    Arguments:\n","        s = Series of strings\n","            Takes a series of strings as an argument\n","            removes any ip addresses\n","    Returns: \n","        Series of strings without ip addresses\n","    '''\n","    ip_pat = '(?:[0-9]{1,3}\\.){3}[0-9]{1,3}'\n","    return s.str.replace(ip_pat, \"\")\n","\n","def strip_whitespace(s):\n","    '''\n","    Arguments:\n","        s = Series of strings\n","            Takes a series of strings as an argument\n","            removes extraneous whitespace\n","    Returns: \n","        Series of strings without extraneous whitespace\n","    '''\n","    \n","    t = s.copy()\n","    # remove whitespace from edge\n","    t = t.str.strip()\n","\n","    # reduce interior whitespace to single space\n","    t = t.str.replace('[\\s]+', ' ')\n","\n","    return t\n","\n","\n","def remove_all_punct(s):\n","    '''\n","    Arguments:\n","        s = Series of strings\n","            Takes a series of strings as an argument\n","            removes all punctuation\n","    Returns: \n","        Series of strings with no punctuation\n","    '''\n","    not_alpha_pattern = '[^A-Za-z\\s]'\n","    return s.str.replace(not_alpha_pattern, \"\")\n","\n","def tidy_series(s):\n","    '''\n","    returns tidied series\n","    '''\n","    # copy series\n","    t = s.copy()\n","\n","    # call individual functions\n","    t = convert_interior_quotes(t)\n","    t = strip_whitespace(t)\n","    t = strip_ip(t)\n","\n","    return t\n","\n"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"E6FBNzeFz_Z3"},"source":["## Apply Cleaning to Full Dataset\n"]},{"cell_type":"code","metadata":{"id":"aIrrLup_eB8n","executionInfo":{"status":"ok","timestamp":1616376297005,"user_tz":300,"elapsed":35569,"user":{"displayName":"Shawn Keech","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicFJvHjGKSkP2elE1kc5WTSumC2FDDidD75Ssv0w=s64","userId":"08670766559094446918"}}},"source":["# tidy comment_text\n","toxic_df['comment_text'] = tidy_series(toxic_df['comment_text'])"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HfuWNkaLxJyq"},"source":["# Feature Engineering\n","\n","There are a few features that are not obvious in the original dataset that may be useful for prediction and classification."]},{"cell_type":"markdown","metadata":{"id":"X1wmz5_OHWd0"},"source":["spaCy: doc and raw"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1UW8V-VHOey0","executionInfo":{"status":"ok","timestamp":1616376297407,"user_tz":300,"elapsed":35944,"user":{"displayName":"Shawn Keech","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicFJvHjGKSkP2elE1kc5WTSumC2FDDidD75Ssv0w=s64","userId":"08670766559094446918"}},"outputId":"99fd51ed-3b06-436e-960e-aaeabff523dd"},"source":["toxic_df.columns"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult',\n","       'identity_hate'],\n","      dtype='object')"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"collapsed":true,"id":"bPCMst5JJF5h","executionInfo":{"status":"ok","timestamp":1616376315148,"user_tz":300,"elapsed":53682,"user":{"displayName":"Shawn Keech","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicFJvHjGKSkP2elE1kc5WTSumC2FDDidD75Ssv0w=s64","userId":"08670766559094446918"}}},"source":["import spacy\n","\n","nlp = spacy.load('en_core_web_lg')"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"BsrgbZVIIJWq","executionInfo":{"status":"ok","timestamp":1616376315148,"user_tz":300,"elapsed":53680,"user":{"displayName":"Shawn Keech","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicFJvHjGKSkP2elE1kc5WTSumC2FDDidD75Ssv0w=s64","userId":"08670766559094446918"}}},"source":["# doc1 = nlp(toxic_df['comment_text'][0])\n","\n","# for x, token in enumerate(doc1):\n","#     print(x, token.lemma_)\n","\n","# textcat = nlp.add_pipe('textcat')\n","# print(nlp.pipeline)"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ww6Ee8ugFqLo","executionInfo":{"status":"ok","timestamp":1616376315149,"user_tz":300,"elapsed":53673,"user":{"displayName":"Shawn Keech","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicFJvHjGKSkP2elE1kc5WTSumC2FDDidD75Ssv0w=s64","userId":"08670766559094446918"}},"outputId":"bf549b15-e82d-498d-d423-7041793ced37"},"source":["%%time\n","\n","def doc_per_row(s):\n","\n","    t = s.copy()\n","    \n","    t = remove_all_punct(t)\n","    t = t.str.strip()\n","\n","    return t.apply(lambda x: nlp(x))"],"execution_count":22,"outputs":[{"output_type":"stream","text":["CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n","Wall time: 5.72 µs\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Rq450eCERmnE"},"source":["%%time\n","toxic_df['doc_raw'] = doc_per_row(toxic_df['comment_text'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RL3Pg8V2kV9o"},"source":["Resource:  \n","- [running pandas operations in parallel](http://www.racketracer.com/2016/07/06/pandas-in-parallel/)  "]},{"cell_type":"code","metadata":{"id":"18A-7gyNjUEF","executionInfo":{"status":"ok","timestamp":1616377214101,"user_tz":300,"elapsed":221,"user":{"displayName":"Shawn Keech","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicFJvHjGKSkP2elE1kc5WTSumC2FDDidD75Ssv0w=s64","userId":"08670766559094446918"}}},"source":["# # parallelize dataframe\n","\n","from multiprocessing import Pool\n","# import multiprocessing\n","\n","# multiprocessing.cpu_count() # 2 for colabs\n","num_partitions = 100\n","num_cores = 2\n","\n","def parallelize_dataframe(df, func):\n","    df_split = np.array_split(df, num_partitions)\n","    pool = Pool(num_cores)\n","    df = pd.concat(pool.map(func, df_split))\n","    pool.close()\n","    pool.join()\n","\n","    return(df)"],"execution_count":34,"outputs":[]},{"cell_type":"code","metadata":{"id":"dK6ddClhlY4_"},"source":["%%time\n","toxic_df['doc_per_row'] = parallelize_dataframe(toxic_df['comment_text'], doc_per_row)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xAEpNVei0Vib"},"source":["classification with spacy\n","\n","- [Really useful article](https://www.machinelearningplus.com/nlp/custom-text-classification-spacy/)  \n","- [another project on kaggle](https://www.kaggle.com/poonaml/text-classification-using-spacy)  \n","- [turbo charge you spacy nlp pipeline](https://towardsdatascience.com/turbo-charge-your-spacy-nlp-pipeline-551435b664ad) \n","- [python & spacy nlp](https://stackabuse.com/python-for-nlp-tokenization-stemming-and-lemmatization-with-spacy-library/)  \n","- [cheat sheet](https://www.datacamp.com/community/blog/spacy-cheatsheet)  \n","\n","\n","Other Resources:\n","- [Naive bayes](https://jakevdp.github.io/PythonDataScienceHandbook/05.05-naive-bayes.html)  \n","\n","Video Resources:\n","- [spacy introduction, tokenization, lemmatization, stemming & techniques](https://www.youtube.com/watch?v=ZIiho_JfJNw)  \n","\n","-\n","\n"]},{"cell_type":"code","metadata":{"id":"94hgfYNqFp8s","executionInfo":{"status":"aborted","timestamp":1616376571548,"user_tz":300,"elapsed":111,"user":{"displayName":"Shawn Keech","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicFJvHjGKSkP2elE1kc5WTSumC2FDDidD75Ssv0w=s64","userId":"08670766559094446918"}}},"source":["%%time\n","\n","def raw_lemma_per_row(s):\n","\n","    t = s.copy()\n","    return t.apply(lambda x: [i.lemma_ for i in x])\n","\n","# test_lemma = raw_lemma_per_row(test)\n","\n","# print(test_lemma)\n","# # raw_lemma_lst = [doc_v.lemma_ for doc_v in raw_doc_list]\n","\n","# # toxic_df['raw_lemma'] = pd.Series(raw_lemma_lst)\n","\n","# type(test_lemma)\n","\n","# print(toxic_df['comment_text'][0])\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PLkUsSJDV4mi","executionInfo":{"status":"aborted","timestamp":1616376571549,"user_tz":300,"elapsed":106,"user":{"displayName":"Shawn Keech","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicFJvHjGKSkP2elE1kc5WTSumC2FDDidD75Ssv0w=s64","userId":"08670766559094446918"}}},"source":["%%time\n","toxic_df['lemma_raw'] = raw_lemma_per_row(toxic_df['doc_raw'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rx7ZhmtkfNuX","executionInfo":{"status":"aborted","timestamp":1616376571551,"user_tz":300,"elapsed":103,"user":{"displayName":"Shawn Keech","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicFJvHjGKSkP2elE1kc5WTSumC2FDDidD75Ssv0w=s64","userId":"08670766559094446918"}}},"source":["toxic_df['lemma_raw'][0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eTXlBXqqfazt","executionInfo":{"status":"aborted","timestamp":1616376571552,"user_tz":300,"elapsed":100,"user":{"displayName":"Shawn Keech","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicFJvHjGKSkP2elE1kc5WTSumC2FDDidD75Ssv0w=s64","userId":"08670766559094446918"}}},"source":["ls\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g5F8LmQcPpBW","executionInfo":{"status":"aborted","timestamp":1616376571552,"user_tz":300,"elapsed":93,"user":{"displayName":"Shawn Keech","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicFJvHjGKSkP2elE1kc5WTSumC2FDDidD75Ssv0w=s64","userId":"08670766559094446918"}}},"source":["# for token in doc1:\n","# #   print(f'{token.text:{20}} {token.lemma_:{20}} {token.pos_:{10}}')\n","#     print(f'{token.lemma_:{20}}')\n","#     # print(f'{token.lemma_:{21}}')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2hD5ZPqZ1g2E"},"source":["## Proportion of All-Caps Type\n","\n","In many circles, typing in all caps is considered a way to indicate yelling. Before changing the initial text, we'll record the proportion of upper case letters to the total number of alphabetical characters. \n","\n","PossibleConfounds:\n","- [People with dislexia occasionally choose all-caps as an accomodataion](https://www.readandspell.com/us/writing-in-all-caps)  \n","- Quoted all-caps text\n","    - not counting quoted and block quoted text may help here.\n","- Text referencing all-caps acronymns\n","- Programming language conventions\n","    - e.g. SQL syntax typically inlcudes all-caps reserved words"]},{"cell_type":"markdown","metadata":{"id":"dqfBTb7-JF2k"},"source":["### Custom Function: uppercase_proportion_column(s)\n"]},{"cell_type":"code","metadata":{"id":"4z1KnAdZ0ApC","executionInfo":{"status":"aborted","timestamp":1616376571553,"user_tz":300,"elapsed":89,"user":{"displayName":"Shawn Keech","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicFJvHjGKSkP2elE1kc5WTSumC2FDDidD75Ssv0w=s64","userId":"08670766559094446918"}}},"source":["def uppercase_proportion_column(s):\n","    '''\n","    given a pandas Series:\n","        containing rows of strings\n","    returns: a series of floats representing\n","        the percentage of capital letters vs total alpha chars\n","        in provided strings\n","    '''\n","    import re # dependent on re\n","\n","    uc_pattern = '[A-Z]'\n","    alpha_pattern = '[A-Za-z]'\n","\n","    cap_count = s.str.findall(uc_pattern).str.len()\n","    # print(cap_count)\n","\n","    alpha_char_count = s.str.findall(alpha_pattern).str.len()\n","    # print(alpha_char_count)\n","\n","    uc_proportion = cap_count / alpha_char_count\n","    # print(uc_proportion)\n","\n","    return uc_proportion"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0H2Buj2GSDU7","executionInfo":{"status":"aborted","timestamp":1616376571553,"user_tz":300,"elapsed":85,"user":{"displayName":"Shawn Keech","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicFJvHjGKSkP2elE1kc5WTSumC2FDDidD75Ssv0w=s64","userId":"08670766559094446918"}}},"source":["doc_lemma = nlp('Practice, practiced, practicing')\n","doc_lemma\n","print(doc_lemma) # can be indexed as a list"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rv2kd0KgSLtj","executionInfo":{"status":"aborted","timestamp":1616376571554,"user_tz":300,"elapsed":81,"user":{"displayName":"Shawn Keech","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicFJvHjGKSkP2elE1kc5WTSumC2FDDidD75Ssv0w=s64","userId":"08670766559094446918"}}},"source":["for token in doc_lemma:\n","    print(token.text, token.lemma_, token.lemma_.lower().strip())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Kse7sDLwYp5P","executionInfo":{"status":"aborted","timestamp":1616376571554,"user_tz":300,"elapsed":76,"user":{"displayName":"Shawn Keech","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicFJvHjGKSkP2elE1kc5WTSumC2FDDidD75Ssv0w=s64","userId":"08670766559094446918"}}},"source":["short_df['uppercase_proportion'] = uppercase_proportion_column(short_df['comment_text'])\n","short_df.columns"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sF18XirY0QoT"},"source":["## Apply Custom Features to Full Dataset"]},{"cell_type":"code","metadata":{"id":"6bOQnYDswWCM","executionInfo":{"status":"aborted","timestamp":1616376571555,"user_tz":300,"elapsed":72,"user":{"displayName":"Shawn Keech","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicFJvHjGKSkP2elE1kc5WTSumC2FDDidD75Ssv0w=s64","userId":"08670766559094446918"}}},"source":["# create uppercase_proportion column\n","toxic_df['uppercase_proportion'] = uppercase_proportion_column(toxic_df['comment_text'])\n","toxic_df.columns"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B_qN8SvmysyP"},"source":["# Simple Train Test Split\n","\n","As our process should first determine whether the text is toxic or not toxic, we'll make a simplified stratified train test split, ensuring our balance of toxic and non toxic rows are proportionally distributed.\n","\n","For now, we won't be too concerned with the proportion of sub-categories, as our first step will be to filter not toxic from toxic, then run parallel operations for each toxic sub-category, as toxic sub-categories are not mutually exclusive."]},{"cell_type":"markdown","metadata":{"id":"vTncCacxukC-"},"source":["## Stratified Split maintaining ratio of toxic to not toxic texts\n"]},{"cell_type":"code","metadata":{"id":"-3rJS3ZRuipN","executionInfo":{"status":"aborted","timestamp":1616376571555,"user_tz":300,"elapsed":67,"user":{"displayName":"Shawn Keech","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicFJvHjGKSkP2elE1kc5WTSumC2FDDidD75Ssv0w=s64","userId":"08670766559094446918"}}},"source":["# split df into X(independent) and y(depenendent) groups\n","ind_cols = ['comment_text', 'uppercase_proportion']\n","\n","X = toxic_df[ind_cols]\n","y = toxic_df.drop(columns=ind_cols)\n","\n","print(f\"X columns: {X.columns}\\ny columns:{y.columns}\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WJZnb8Pl1Stk","executionInfo":{"status":"aborted","timestamp":1616376571556,"user_tz":300,"elapsed":63,"user":{"displayName":"Shawn Keech","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicFJvHjGKSkP2elE1kc5WTSumC2FDDidD75Ssv0w=s64","userId":"08670766559094446918"}}},"source":["# Train Test Split. Stratified on y['toxic']\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, \n","                                                    test_size=0.33, \n","                                                    random_state=42, \n","                                                    stratify=y['toxic'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"egZZdQA3hS2u"},"source":["# spaCy\n","\n","Let's try out spaCy, a nlp processing library!\n","\n","- https://course.spacy.io/en/chapter1\n","- [text classification with spaCy](https://www.dataquest.io/blog/tutorial-text-classification-in-python-using-spacy/) \n","- [customized list of stopwords](https://spacy.io/usage/linguistic-features#stop-words)  \n","- [Split Series into list of sentences](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.cat.html)  \n","- [contractions](https://theslaps.medium.com/cant-stand-don-t-want-contractions-with-spacy-39715cac2ebb)  \n"]},{"cell_type":"code","metadata":{"id":"lVvUNZThCrZg","executionInfo":{"status":"aborted","timestamp":1616376571556,"user_tz":300,"elapsed":59,"user":{"displayName":"Shawn Keech","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicFJvHjGKSkP2elE1kc5WTSumC2FDDidD75Ssv0w=s64","userId":"08670766559094446918"}}},"source":["# # check version\n","! python -m spacy info"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d4D7rYTjHXYY"},"source":["## adjusting pipeline with small data subset"]},{"cell_type":"code","metadata":{"id":"qpktZODb8bOY","executionInfo":{"status":"aborted","timestamp":1616376571556,"user_tz":300,"elapsed":53,"user":{"displayName":"Shawn Keech","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicFJvHjGKSkP2elE1kc5WTSumC2FDDidD75Ssv0w=s64","userId":"08670766559094446918"}}},"source":["# sentence tokinization\n","nlp = English()\n","\n","# add the component to the pipeline\n","nlp.add_pipe('sentencizer')\n","\n","text = short_df['comment_text'].str.cat(sep=\" \")\n","\n","# 'nlp' object is used to create documents with linguistic annotations\n","doc = nlp(text)\n","\n","sents_list = [sent.text for sent in doc.sents]\n","\n","print(len(sents_list))\n","print(sents_list[0:3])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ne-YezVL_8rr","executionInfo":{"status":"aborted","timestamp":1616376571557,"user_tz":300,"elapsed":48,"user":{"displayName":"Shawn Keech","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicFJvHjGKSkP2elE1kc5WTSumC2FDDidD75Ssv0w=s64","userId":"08670766559094446918"}}},"source":["token_list = [token.text for token in doc]\n","print(token_list)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IVuQcUihBiiS","executionInfo":{"status":"aborted","timestamp":1616376571557,"user_tz":300,"elapsed":44,"user":{"displayName":"Shawn Keech","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicFJvHjGKSkP2elE1kc5WTSumC2FDDidD75Ssv0w=s64","userId":"08670766559094446918"}}},"source":["# for token in doc:\n","#     print(token.text, token.pos_, token.i)\n","\n","for word in doc[0:10]:\n","    print(word.text, word.lemma_, word.pos_)\n","    \n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0vUG21gj8a2K"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"nMNCTHA7oIMs"},"source":["# NLTK Naive Bayes\n"]},{"cell_type":"code","metadata":{"id":"j6Ad7j6gofEf","executionInfo":{"status":"aborted","timestamp":1616376571558,"user_tz":300,"elapsed":40,"user":{"displayName":"Shawn Keech","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicFJvHjGKSkP2elE1kc5WTSumC2FDDidD75Ssv0w=s64","userId":"08670766559094446918"}}},"source":["# ! pip install --user -U nltk\n","# ! pip install sklearn"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZhjhN7nniACA","executionInfo":{"status":"aborted","timestamp":1616376571558,"user_tz":300,"elapsed":35,"user":{"displayName":"Shawn Keech","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicFJvHjGKSkP2elE1kc5WTSumC2FDDidD75Ssv0w=s64","userId":"08670766559094446918"}}},"source":["# from nltk.classify import naivebayes\n","\n","# from sklearn.svm import LinearSVC\n","from nltk.classify.scikitlearn import SklearnClassifier\n","# classif = SklearnClassifier(LinearSVC())\n","\n","from sklearn.feature_extraction.text import TfidfTransformer\n","from sklearn.feature_selection import SelectKBest, chi2\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.pipeline import Pipeline\n","\n","\n","pipeline = Pipeline([('tfidf', TfidfTransformer()),\n","                     ('chi2', SelectKBest(chi2, k=1000)),\n","                     ('nb', MultinomialNB())])\n","classif = SklearnClassifier(pipeline)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b8w-SaNNqm8Y","executionInfo":{"status":"aborted","timestamp":1616376571559,"user_tz":300,"elapsed":30,"user":{"displayName":"Shawn Keech","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicFJvHjGKSkP2elE1kc5WTSumC2FDDidD75Ssv0w=s64","userId":"08670766559094446918"}}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lBIF3S3aNgPt","executionInfo":{"status":"aborted","timestamp":1616376571559,"user_tz":300,"elapsed":26,"user":{"displayName":"Shawn Keech","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicFJvHjGKSkP2elE1kc5WTSumC2FDDidD75Ssv0w=s64","userId":"08670766559094446918"}}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BcAdz69RyFvN"},"source":["# SKLearn \n","\n","- Resources: \n","[Naive Bayes Classification ](https://jakevdp.github.io/PythonDataScienceHandbook/05.05-naive-bayes.html)  "]},{"cell_type":"code","metadata":{"id":"oZQZmkaAyD-A","executionInfo":{"status":"aborted","timestamp":1616376571560,"user_tz":300,"elapsed":22,"user":{"displayName":"Shawn Keech","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicFJvHjGKSkP2elE1kc5WTSumC2FDDidD75Ssv0w=s64","userId":"08670766559094446918"}}},"source":["# imports\n","%matplotlib inline\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns; sns.set()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"t8YAxtxGyeIi","executionInfo":{"status":"aborted","timestamp":1616376571560,"user_tz":300,"elapsed":18,"user":{"displayName":"Shawn Keech","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicFJvHjGKSkP2elE1kc5WTSumC2FDDidD75Ssv0w=s64","userId":"08670766559094446918"}}},"source":[""],"execution_count":null,"outputs":[]}]}