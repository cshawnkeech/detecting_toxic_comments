{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "from spacy.lang.en import English\n",
    "spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "from spacy.tokens import Doc\n",
    "# import en_core_web_lg\n",
    "# nlp = spacy.load('../models/spacy_multi_cat_model/')\n",
    "nlp = spacy.load(\"../models/spacy_2/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# add src folder to path\n",
    "sys.path.insert(1, '../src')\n",
    "\n",
    "# from text_prep import tidy_series, uppercase_proportion_column\n",
    "from spacy_helper import doc_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "one_text = '''\n",
    "Ok, let me say it again Come on, now you guys are just being piece of shit jews. I mean you have to admit, the guys in pink floyd play their instruments about as slow as a nigger works. I shouldn't even call what they play music. It's just a bunch of alarm clocks and cashier regirsters! But you know what the most pretentious thing about them is, its their lyrics. All af their songs are just surrealist poetry sung over doom-noise pop, and everyone starts calling them genius's over it. The truth is, their songs have no meaning. Take the album 'The Wall' for instance; sure it tells a story, but what is the moral and the meaning of the story? And dont tell me that the purpose of their songs is to make you think. The only way that music as slow as pink floyd could make you fucking think is if you were just as stoned as they are, which you kikes probly are... And one last time: 1) pink floyd fucking sucks 2) david fuckmor should taste my ass 3) you should to\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TOXIC': 0.9894261360168457,\n",
       " 'SEVERE_TOXIC': 0.007514932658523321,\n",
       " 'OBSCENE': 0.9430854916572571,\n",
       " 'THREAT': 0.007477084174752235,\n",
       " 'INSULT': 0.917741596698761,\n",
       " 'IDENTITY_HATE': 0.7508668899536133}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc=nlp(one_text)\n",
    "doc.cats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Before 5 epochs  \n",
    "{'TOXIC': 0.9983283877372742,  \n",
    " 'SEVERE_TOXIC': 0.0003475894336588681,  \n",
    " 'OBSCENE': 0.2968767285346985,  \n",
    " 'THREAT': 0.0011758265318349004,  \n",
    " 'INSULT': 0.20628367364406586,  \n",
    " 'IDENTITY_HATE': 0.00019311188952997327}  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## After 5 epochs  \n",
    "{'TOXIC': 0.9834251999855042,  \n",
    " 'SEVERE_TOXIC': 0.07075302302837372,  \n",
    " 'OBSCENE': 0.8929150104522705,  \n",
    " 'THREAT': 0.0113288052380085,  \n",
    " 'INSULT': 0.8754300475120544,  \n",
    " 'IDENTITY_HATE': 0.3847048282623291}  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After 25 epochs  \n",
    "  \n",
    "{'TOXIC': 0.9894261360168457,  \n",
    " 'SEVERE_TOXIC': 0.007514932658523321,  \n",
    " 'OBSCENE': 0.9430854916572571,  \n",
    " 'THREAT': 0.007477084174752235,  \n",
    " 'INSULT': 0.917741596698761,  \n",
    " 'IDENTITY_HATE': 0.7508668899536133}  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting info from preserved spaCy docs\n",
    "\n",
    "I've had a little difficulty with getting the doc properties to un-pickle and maintain the ability to further process them later. docs seem to depend on some vocab properties of the model that are not saved within the doc itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 38s, sys: 28.4 s, total: 4min 6s\n",
      "Wall time: 4min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "'''\n",
    "CPU times: user 3min 44s, sys: 33.5 s, total: 4min 17s\n",
    "Wall time: 4min 32s\n",
    "'''\n",
    "X_train = pd.read_pickle('../data/basic_df_split/X_train_2-1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_2-1.pkl         basic_X_test.pkl        basic_y_test.pkl\n",
      "X_train_docs_series.pkl basic_X_train.pkl       basic_y_train.pkl\n"
     ]
    }
   ],
   "source": [
    "# load y_train\n",
    "! ls ../data/basic_df_split/\n",
    "y_train = pd.read_pickle('../data/basic_df_split/basic_y_train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27301     (', Meša, Selimović, I, 'm, not, opposing, suc...\n",
       "141668    (', September, 2008, (, UTC, ), Talking, about...\n",
       "Name: docs, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "tiny_doc_sample = X_train['docs'].head(2)\n",
    "tiny_doc_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiny_lemmas = tiny_doc_sample.apply(lambda doc: [nlp.vocab[tok.lemma].vector for tok in doc if doc_check(tok) and tok.has_vector])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tiny_lemmas[27301])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['comment_text', 'uppercase_proportion', 'docs', 'lemmas', 'doc_vectors',\n",
       "       'tok_vectors'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27301     [-0.019261397, 0.1402782, -0.17225473, -0.0019...\n",
      "141668    [-0.14023165, 0.22500116, -0.07992911, -0.0451...\n",
      "104554    [0.0006661963, 0.2898478, -0.053957734, 0.0774...\n",
      "118561    [-0.034046583, 0.17167076, -0.03414113, -0.051...\n",
      "100409    [-0.07457596, 0.19859332, -0.21044752, -0.0248...\n",
      "                                ...                        \n",
      "153719    [-0.053927306, 0.14099398, -0.12922487, -0.099...\n",
      "148645    [-0.04553457, 0.20419797, -0.14104365, -0.0279...\n",
      "113159    [-0.04607839, 0.13241082, -0.17935269, -0.0352...\n",
      "104771    [-0.24597338, 0.28444514, -0.07856212, -0.1289...\n",
      "14596     [-0.12666084, 0.06894974, -0.2519976, -0.13606...\n",
      "Name: doc_vectors, Length: 106912, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# print(y_train['toxic'].head())\n",
    "print(X_train['doc_vectors'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Where I Left Off\n",
    "\n",
    "https://medium.com/@awantikdas/a-comprehensive-naive-bayes-tutorial-using-scikit-learn-f6b71ae84431"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nb_toxic_yn_doc_vect = BernoulliNB()\n",
    "\n",
    "# nb_toxic_yn_doc_vect.fit(X_train['doc_vectors'], y_train['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, ComplementNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils.extmath import density\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create list of lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 538 ms, sys: 103 ms, total: 641 ms\n",
      "Wall time: 649 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lemma_words = list()\n",
    "\n",
    "for lst in X_train['lemmas']:\n",
    "    for word in lst:\n",
    "        lemma_words.append(word)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counter for lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_counter = Counter(lemma_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3151394\n",
      "[('article', 49387), ('page', 38252), ('wikipedia', 30307), ('talk', 25655), ('edit', 23369), ('like', 19462), ('think', 16678), ('know', 16297), ('source', 15575), ('thank', 15039)]\n",
      "116496\n"
     ]
    }
   ],
   "source": [
    "# 3151394 total lemmas in lemma_words\n",
    "print(len(lemma_words))\n",
    "\n",
    "print(lemma_counter.most_common(10))\n",
    "\n",
    "# 116496 unique lemmas\n",
    "print(len(lemma_counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk imports\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "'''\n",
    "CPU times: user 246 ms, sys: 21.2 ms, total: 268 ms\n",
    "Wall time: 276 ms\n",
    "'''\n",
    "print(type(stopwords.words('english')))\n",
    "\n",
    "stopw_set = set(stopwords.words('english'))\n",
    "\n",
    "# lemma_less = [lemma for lemma in lemma_words if lemma not in stopw_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nlemma_less length:    3135975\\nreduced lemmas by:      15419\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "lemma_less length:    3135975\n",
    "reduced lemmas by:      15419\n",
    "'''\n",
    "\n",
    "# print(f'lemma_less length: {len(lemma_less):10}')\n",
    "# print(f'reduced lemmas by: {len(lemma_words) - len(lemma_less):10}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nlemma_less_counter length:     116427\\nreduced lemma_counter by:          69\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "lemma_less_counter length:     116427\n",
    "reduced lemma_counter by:          69\n",
    "'''\n",
    "# lemma_less_counter = Counter(lemma_less)\n",
    "# print(f'lemma_less_counter length: {len(lemma_less_counter):10}')\n",
    "# print(f'reduced lemma_counter by:  {len(lemma_counter) - len(lemma_less_counter):10}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF*IDF\n",
    "\n",
    "Working through techniques from lecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27301     [meša, selimović, oppose, formulation, instead...\n",
       "141668    [september, utc, talk, victimize, release, imp...\n",
       "104554    [august, utc, danke, support, find, need, ask,...\n",
       "118561    [aurora, part, story, particularly, weak, auro...\n",
       "100409    [wp, w, wikipedia, manual, text, give, instruc...\n",
       "Name: lemmas, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['lemmas'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 985 ms, sys: 507 ms, total: 1.49 s\n",
      "Wall time: 1.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# remove lemmas that appear in nltk stopword list\n",
    "X_train['lemmas_less'] = X_train['lemmas'].apply(lambda row: [lemma for lemma in row if lemma not in stopw_set])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf(processed_doc):\n",
    "    '''\n",
    "    from lecture.\n",
    "    \n",
    "    calculates the term frequency for every word in a document\n",
    "    \n",
    "    processed_doc is a list of words that have already had processing applied\n",
    "    '''\n",
    "    # word counts from Counter\n",
    "    counts = Counter(processed_doc).most_common()\n",
    "    \n",
    "    # total_words is just the sum of all the counts in our counter\n",
    "    total_words = sum([count for word, count in counts])\n",
    "    \n",
    "    # tf is a tuple of the word and the count for that word / total word count.\n",
    "    tf = [(word, count/total_words) for word, count in counts]\n",
    "    return dict(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.92 s, sys: 1.03 s, total: 2.95 s\n",
      "Wall time: 5.43 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create column with tf information per document\n",
    "X_train['tf'] = X_train['lemmas_less'].apply(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'writer': 0.1, 'try': 0.06666666666666667, 'view': 0.06666666666666667, 'bosnian': 0.06666666666666667, 'serbian': 0.06666666666666667, 'yugoslavian': 0.06666666666666667, 'meša': 0.03333333333333333, 'selimović': 0.03333333333333333, 'oppose': 0.03333333333333333, 'formulation': 0.03333333333333333, 'instead': 0.03333333333333333, 'prevent': 0.03333333333333333, 'potential': 0.03333333333333333, 'editwar': 0.03333333333333333, 'inclusion': 0.03333333333333333, 'option': 0.03333333333333333, 'mention': 0.03333333333333333, 'read': 0.03333333333333333, 'cumbersome': 0.03333333333333333, 'maybe': 0.03333333333333333, 'worth': 0.03333333333333333, 'good': 0.03333333333333333, 'talk': 0.03333333333333333}\n",
      "0.9999999999999999\n"
     ]
    }
   ],
   "source": [
    "# peek at values\n",
    "print(X_train['tf'].iloc[0])\n",
    "print(sum(X_train['tf'].iloc[0].values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocabulary_from_s(series):\n",
    "    '''\n",
    "    get vocabulary from series of lists of lemmas\n",
    "    '''\n",
    "    # get unique set of tokens\n",
    "    s = series.apply(lambda x: set(x))\n",
    "    \n",
    "    vocabulary = set()\n",
    "    \n",
    "    s.apply(lambda x: vocabulary.update(x))\n",
    "    \n",
    "    return vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idf(corpus, vocabulary=None):\n",
    "    '''\n",
    "    calculates the inverse document frequency\n",
    "    '''\n",
    "    \n",
    "    # get the vocabulary if None\n",
    "    if vocabulary == None:\n",
    "        vocabulary = get_vocabulary(corpus)\n",
    "\n",
    "    # the top portion of the fraction in the log\n",
    "    number_of_docs = len(corpus)\n",
    "\n",
    "    docs = [set(doc) for doc in corpus]\n",
    "    \n",
    "    # create a list to store the tuples of (\"word\", idfvalue)\n",
    "    idf_values = []\n",
    "    # iterate through all words in the vocabulary to calculate idf values\n",
    "    for word in vocabulary:\n",
    "        # [doc for doc in docs if word in doc] is list of documents containing the word.\n",
    "        docs_which_contain_the_word = [doc for doc in docs if word in doc]\n",
    "        number_of_docs_with_word = len(docs_which_contain_the_word)\n",
    "        # append the idf value to our list\n",
    "        idf_values.append((word, np.log(number_of_docs / number_of_docs_with_word)))\n",
    "    # return as a dictionary\n",
    "    return dict(idf_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.39 s, sys: 836 ms, total: 2.23 s\n",
      "Wall time: 4.15 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Get training corpus vocabulary\n",
    "X_train_vocab = get_vocabulary_from_s(X_train['lemmas_less'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_vocab is a set with 116427 values\n"
     ]
    }
   ],
   "source": [
    "print(f'X_train_vocab is a set with {len(X_train_vocab)} values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nb', 'ŀ', 'ö', 'ef', 'ʎ', 'xz', '牛岩', 'gz', 'ps', 'î', 'ν', 'вы', 'mh', 'gq', 'ai', 'қ', 'si', 'dh', 'ʊ', 'ვ', 'r', 'ϸ', 'bz', 'ʡ', '雲水', 'ɢ', 'pr', 'bt', 'iw', '𐌲', 'въ', 'من', 'π', 'ή', 'ō', 'ŷ', 'þ', 'wp', 'jp', 'se', 'μm', 'sq', 'чи', 'ey', 'kg', 'œ', '濤', 'aç', '討論', 'ns', 'ed', 'za', 'ac', '咨', 'bs', 'cs', 'cứ', 'dm', 'ĭ', 'ħ', 'rt', 'θ', 'ń', 'ü', 'כל', 'ur', 'æ', 'sr', 'iy', 'tn', 'ě', 'eø', 'tz', 'ŗ', '対馬', '竹島', 'º', 'ʒ', 'im', 'lj', 'hb', 'ő', 'mg', 'fs', 'ǫ', 'fv', 'ny', '𒁳', '青い', 'fy', 'wk', 'р', 'λ', 'gf', '先聖', 'ŋ', 'χo', 'ʲ', 'xi', 'ha', 'τη', 'uj', 'yy', 'sy', 'lr', 'ā', 'مر', 'dd', 'sc', 'rw', 'זו', 'el', 'ṛ', 'fr', 'sb', 'ˠ', 'uo', 'sẽ', 'tự', '粵語', 'ws', 'ム', 'wa', 'ó', 'hg', 'ku', 'et', 'جا', 'uy', 'ʂ', 'fk', 'би', 'ш', 'qc', 'ar', 'av', 'nx', 'tq', '姓', 'cd', 'ℳ', 'ճ', 'я', 'œf', 'jg', 'fn', 'vr', 'ɜ', '縣', 'tv', 'hv', 'חג', 'gs', 'ck', 'yk', 'qs', 'ax', 'ĵ', '卐', 'ÿ', 'ɻ', 'ju', 'jə', 'yd', 'ig', 'tm', 'wr', 'hi', 'tk', 'je', 'v', 'kv', 'мы', '盒', 'es', 'pc', 'pg', 'i̇', 'ь', 'ỹ', 'q', 'yu', 'jr', 'ღ', 'gm', 'bq', 'φ', '河', 'yo', 'lg', '틀', 'iv', 'ɰ', 'cg', 'mt', 'op', 'ow', 'на', 'tj', 'ʐ', 'ǂ', 'ḹ', 'pj', 'ǁ', 'nj', 'ú', 'ſ', 'gv', 'pa', '百越', 'ev', 'th', 'ʝ', 'ġ', 'ś', 'ў', 'oc', 'ад', 'iċ', 'ņ', 'ψ', 'xy', 'ɹ', 'bj', 'ry', 'س', 'ec', 'il', 'ky', 'х', 'óg', 'qq', 'bi', 'ri', 'li', 'rl', 'fd', 'fb', '松涛', 'zg', 'í', 'uf', 'pé', '보호', 'w', '八字', 'ͳ', 'xd', 'cn', 'ŕ', 'ji', 'qi', 'à', 'rm', 'ci', 'hm', 'u', 'nw', 'γε', 'طی', 'pu', 'aw', 'hl', 'bm', 'ॐ', 'ǌ', 'ti', 'ʔ', 'yb', 'bd', 'hh', 'ο', '涛', 'й', 'ĝ', 'ţ', 'wm', 'sh', '总督', 'de', 'ɨ', 'та', 'l', 'gp', 'hê', 'ät', 'ε', 'û', 'kt', 'ώ', 'oj', 'ºe', 'lx', 'τ', 'из', 'oy', '豆田', 'ɭ', 'он', 'ff', 'δo', 'ay', 'э', 'л', 'és', 'væ', 'jd', 'ɯ', 'و', 'sl', 'wt', 'غ', 'ऋ', 'tú', 'h', '穣', 'cz', 'wy', 'lō', 'ho', 'ű', 'ṝ', 'pb', 'gu', 'vf', 'ý', 'ṇ', '容', 'aa', 'oa', 'ũ', 'hs', '劉焉', 'sο', 'qa', '北京', 'ђ', 'hk', 'tο', 'dy', 'ao', 'hu', 'le', 'eq', 'ها', 'את', 'rs', 'দ', 'br', 'tr', 'ʋ', 'ox', '公', 'na', 'σ', 'km', 'ㅅ', 'aṃ', 'בא', '翻訳', 'az', 'tf', 'če', 'же', '요청', 'cf', 'ż', 'cc', '隻', 'em', 'mc', 'lá', '竜龙', 'н', 'vc', 'xj', 'fg', 'dn', 'hp', 'خ', 'n', 'ū', 'jw', 'df', 'є', 'у', 'sg', '小', 'bg', 'ľ', 'ab', 'ix', '谢谢', 'xb', 'dq', 'ר', '南西', 'т', 'vs', 'cá', 'dc', 'ɗ', '琉竜', 'शक', 'за', 'pz', 'ʉ', 'нп', 'ţo', 'ფ', 'cq', '先生', 'от', 'ii', 'ul', 'mw', 'ǜ', 'ww', 'ну', 'ˑ', 'uv', 'ᶏ', 'mf', 'io', 'ɳ', 'dø', 'ů', 'ep', 'vj', 'ir', 'js', 'ķ', 'χ', 'ĺ', 'da', 'ʟ', 'η', 'ɽ', 'οφ', 'ap', 'jc', 'ɣ', 'oz', 'är', 'dw', 'ñ', 'qf', 'pw', 'ы', 'έ', 'ω', 'ς', 'xt', 'її', 'qe', 'ɴ', 'ŧ', 'zu', '明溪', 'x', 'xu', 'ak', 'ë', 'fé', 'tp', 'ɛ', '군', 'ː', 'ml', 'og', 'ls', 'mb', 'fc', 'µg', 'lt', 'ø', 'dv', 'ly', 'ζ', 'м', 'ga', 'g', 'ň', 'ò', '部', 'ʘ', 'ǃ', 'ϻ', 'tw', 'τῷ', 'é', 'fz', '陈登', 'να', '松', 'ѕ', 'bc', 'ŝ', 'øf', 'ɔ', 'po', 'wj', 'ds', '川', 'ă', 'ṃ', 'te', 'ˉˉ', 'ć', 'co', 'kp', 'kd', '받침', 'ɓ', 'ob', 'ct', 'xr', 'tá', 'ɘ', 'gò', 'uh', 'iː', 'kb', 'mi', 'xx', 'ɡ', 'jj', 'ɖ', 'mz', 'τε', 'ą', 'ni', 'đ', 'k', '先公', 'ki', '문서', 'ď', 'kf', 'wl', 'ie', 'nn', 'fu', 'ʧ', '連絡', 'ʄ', 'bu', 'ˡ', 'oe', 'ǔ', 'db', 'tu', 'jɐ', '史记', 'iе', 'ḍ', 'zt', 'dz', 'nk', 'cm', 'ɦ', 'п', 'ù', 'けい', 'rp', '개는', 'ز', 'ut', '華人', 'vn', 'rg', 'lo', 'во', 'wc', 'tt', 'ό', 'od', 'ks', 'ŭ', 'α', 'ze', 'bo', 'xp', 'ka', 'ᛏ', 'fm', 'δ', 'स', 'fi', 'qg', 'ʈ', 'rr', 'β', 'id', 'fp', 'gc', 'ĩ', 'ź', 'ṣ', 'fw', 'wg', 'δt', 'ȳ', 'ål', 'ya', '外', 'jk', 'pv', 'ќ', 'ė', 'xf', 'ue', 'ɪ', 'un', 'hy', 'jz', '迷惑', 'קו', 'xm', 'eu', 'ym', 'tl', 'zq', 'uw', 'hn', '投稿', 'ʌ', 'с', '구역', 'vv', 'ʁ', 'ex', 'ц', 'e', 'ug', 'tø', 'mj', 'ip', 'vw', 'ιν', 'ɲ', 'ql', 'ér', 'oh', 'nā', 'di', 'ʌe', 'ɸ', 'qu', 'nc', 'ro', 'gj', '번역', 'mm', 'ô', 'yt', 'fa', 'gb', '𐌰𐌿', 'ot', 'kq', 'ɕ', 'né', 'rc', '曹操', 'ng', 'ph', 'ф', 'af', 'è', 'cy', 'υ', 'ḥ', 'ע', 'ŏ', 'kk', 'ih', 'su', 'ж', 'hj', 'ǽ', 'rb', 'ta', 'ъ', 'zj', 'ї', 'ğ', 'ej', '琉球', 'ia', 'zh', 'yr', 'ĥ', 'ge', 'ɺ', 'lv', 'np', 'ɵ', 'ǘ', 'ov', '小刀', 'py', '副王', 'ko', 'sv', 'cx', 'td', 'ae', 'um', 'sw', 'pl', '吕布', 'cv', '𐌴𐌹', 'wb', 'ux', '독도', 'oo', 'hw', 'rn', 'ss', 'cl', 'ɬ', 'ʰ', 'sn', 'ɒ', 'nz', 'با', 'uí', 'ǐ', 'з', 'tb', 'mr', 'ft', 'mu', 'kw', 'mo', 'ɝ', 'pt', 'dj', 'go', 'iə', '說嗎', 'ä', '刀', 'bl', 'го', 'в', '臧洪', 'uk', '声援', 'cp', 'dk', 'wv', 'kl', 'hf', 'יג', 'gd', 'pe', 'iu', 'j', '中国', 'eh', 'mp', 'vq', 'ž', 'fl', 'ã', 'ģ', 'ee', 'ub', 'aj', 'fe', 'ב', 'ḷ', 'श', '会話', 'rd', 'δρ', 'پل', 'ɾ', 'cw', 'vt', 'ʜ', 'iq', 'ウィ', 'ɟ', 'ɱ', 'fx', 'dr', 'ı', 'од', 'ch', 'љ', 'nd', 'zs', 'τα', 'b', 'gl', 'xs', 'по', 'sz', 'jf', 'ʑ', '頭', 'vp', 'ī', '竜龍', 'f', 'nf', 'مي', 'jm', 'gt', '빠', 'pd', 'ˤ', 'ų', 'z', 'st', 'sj', 'sa', 'ċ', 'bó', 'nl', 'ξ', 'wd', 'ê', 'ra', 'ϟ', 'wz', 'eo', 'på', 'nu', 'ɶ', '桔了', 'як', 'ɞ', 'ok', 'bp', 'čt', 'ne', 'ǀ', 'xl', 'ʷ', 'ua', 'qv', 'а', 'ms', 'md', 'du', 'wá', 'å', '内', 'hq', 'ви', 'jl', 'ћ', 'bw', 'uc', 'dx', 'gh', 'ʀ', 'إن', 'تا', 'bâ', 'vu', 'hz', 'ét', 'om', 'ρε', 'أو', 'qw', 'ни', 'pf', 'bb', 'ツ', 'ty', 'lw', 'ϛ', 'jb', 'ǣ', 'ag', 'ic', 'nv', 'ín', 'mə', 'ƒ', 'gk', 'б', 'dg', 'dl', 'đi', '閩語', 'δm', 'eg', 'hd', 'ˌ', '郭', 'yg', 'ř', 'c', 'ʢ', 'ǒ', 'ẽ', 'la', 'lp', '獨島', '見学', 'њ', 'lc', 'jo', 'wo', 'zf', 'ĉ', 'ln', 'zə', 'gi', 'pi', 'vb', 'ου', 'cu', '永訣', 'і', 'ş', 'ht', 'vd', 'ɠ', 'zx', 'cr', 'ud', 'là', 'ℱ', 'lk', 'mn', 'lf', 'ʕə', 'ē', 'al', 'mí', 'ja', 'ά', 'ǖ', 'rk', 'ʏ', 'vk', 'vh', 'į', '翻译', 'p', 'ͱ', 'wu', '龱', 'هه', 'xg', 'фc', '島', 'bv', 'е', 'bk', 'ð', 'sf', '謝謝', 'rv', 'mk', 'vä', 'aq', '八', 'ib', 'rj', 'rx', '橘子', 'č', 'до', '排便', 'lb', 'גם', 'ʕa', 'vm', 'lm', 'да', 'ѓ', 'ɫ', 'ʛ', 'uz', 'ⁿ', 'sk', 'gr', 'ɚ', 'au', 'ч', 'kö', 'yv', 'pq', 'ç', 'då', 'bf', 'ea', 'jō', 'ld', 'г', 'ba', 'rh', '张邈', 'ǚ', 'ß', 'jn', 'ŵ', 'bh', 'כן', 'ɑe', 'ɮ', 'gg', 'pm', 'uu', 'ύ', 'ṭ', '占地', 'pk', 'kj', 'ʕ', 'où', 'ʃ', 'â', 'αι', 'yn', 'ou', 'ǎ', '𐌰𐌹', 'fæ', 'cj', 'gw', 'hr', 'μ', 'từ', 'sì', 'sm', 'ϝ', 'vg', 'ʙ', '공군', 'ю', 'ɥ', 'xo', 'في', 'có', 'va', 'щ', 'fo', 'אז', 'ј', 'ё', 'к', 'то', 'ek', 'nm', 'vi', 'yi', 'bn', 'tg', 'xa', 'ei', 'qm', 'wn', 'ł', 'ɐ', 'ㄷ', 'ez', 'er', 'hộ', 'oi', '편집', 'bx', 'yh', 'uq', 'ę', 'ə', 'ļ', 'ĕ', '只', 'á', 'dt', 'vo', 'ι', 'lh', 'ɧ', '吳語', 'kn', 'ʍ', '華僑', 'ص', '很好', 'że', 'ℚ', 'ah', 'os', 'sp', 'pp', '때려', 'ì', 'cb', 'pn', 'px', 'ts', 'š', 'qb', 'sí', 'eb', 'џ', 'ˈ', 'и', '飞天', 'dp', 'jv', 'よ', 'ґ', 'ce', 'lu', 'rf', 'ɑ', 'ウェ', 'ys', 'ke', 'ad', 'iz', 'ï', 'tc', 'hc', 'ew', 'ɤ', 'nh', 'д', 'ↄ', 'ui', 'ти', 'κ', 'о', 'ρ', 'sd', 'не', 'mv', 'ť', 'ye', 'nt', 'ще', 'xv', 'õ', 'और', 'γ', 'nr', '中平', 'бы', 'uṗ', 'wi', 'أن', 'ί', 'tx', 'en', 'ik', 'iţ', 'ru', 'kc', 'wh']\n"
     ]
    }
   ],
   "source": [
    "print([i for i in X_train_vocab if len(i) <= 2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['deletionaddictionteam', 'appreciatedespecially', 'pseudoantidisestablishmentarianism', 'kennnnnnnnnnnnnnnnnnnnnnnnnnnnnnedddddddddddddddddddddyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyy', 'lololololololololpenis', 'peeeeeeeeeeniiiiiiiiiiiiisssss', 'mattcryptotabsnoswpinner', 'couldyoufixsevillaplease', 'moooovvvvvveeeeeeeeeerrrrrrrrr', 'woooooooooooooooooooo', 'titlewithoutnamespace', 'nooooooooooooooooooooooooooooootable', 'blahhhhhhhhhhhblahhhhhhhhhblahblahblah', 'peoplesfreesaveliytalk', 'armchairvexillogistdon', 'sooooooooooooooooooooo', 'hahahahahahahahahahahahaahhahahahahaahhahahahahahahaha', 'vertebralcompressionfractures', 'honorificabilitudinitatibus', 'gothaparduskerialldrapolatkh', 'superflyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyy', 'consensusnotwithstande', 'umsomekindofendinghere', 'weburiedoursecretsinthegarden', 'revolvingpersonalityconduct', 'drivesfastturnsleftandright', 'douuuchhhheeeebaggggggg', 'ssssssssssssshhhhhhhh', 'marktwainatmarktwaineshouston', 'zzzzzzzzzzzzzzzzzzzzz', 'quantumelectrodynamic', 'ohhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh', 'msnbccbsnbcnprpbsabcreuters', 'aolanaonwaswronglyaccused', 'newssportsgossipgatecrasherrush', 'weeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee', 'starcheerspeaksnewslostwars', 'pleeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee', 'yyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyy', 'shhhhhiiiiiiiifffffffftttttttt', 'lolololololololololololololololololololololololololololololololololololololololololololololololololololololololololololololololololololololololololololololololololololololololololololololololololololololololololololololololol', 'theclownprinceofcrime', 'rascistariaciaitiaracistracistaricszarghghghghghhghghghg', 'yoooooooooooooooouuuuuuuuuuuuuuuuuuuuuu', 'blockedbeyondalleternity', 'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaany', 'randomracialslurresearcher', 'yeeeeeeeaaahhhhhboiiiiii', 'aaaaaaaaaahhhhhhhhhhhhhh', 'campusambassadorprofile', 'guidelatinovideoblogsall', 'fornminnesföreningens', 'sooooooooooooooooooooooooooo', 'notthewikipediaweekly', 'servicedestinationfrequencyjourney', 'mrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr', 'noooooooooooooooooooooooooooooooooooooooo', 'oliverwolcottwasanobody', 'hahahahahahahahahahhaahahhahahaahhahahahahahahahahahahahahahahahahahahahah', 'blahblahblahblahnlahnlahblahblha', 'sozialwissenschaftlicher', 'shuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuut', 'hahahahahahahahahahaha', 'gaaaaaaaaaaaaaaaaaaaaaaaaay', 'shitshitshitcockshitcockshittycock', 'neeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeerd', 'armchairvexillologistdon', 'yooioooooooooooooooooooooooooooooooou', 'bwaaaaaaaaaaaahahahahaahaha', 'lolololololololollololololololllolololololololololo', 'ipimpoutfaggotsforcfully', 'republicanjackoffdyke', 'gayyyyyyyyyyyyyyyyyyyyyyyy', 'hahahahahaahahahahahahahahahahahahahahaha', 'organharvestinvestigation', 'booooooooohooooooooooooo', 'fuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuck', 'wwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwww', 'relationshipenjoyment', 'residentanthropologist', 'turkiclanguagesgroups', 'ahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahah', 'commonsnotificationbot', 'okkkkkkkkkkkkkaaaaaaaaaayyyyyyyyyyyyy', 'archbelwtfishisnameanyway', 'noooooooooooooooooooooo', 'thiopropylphenylethylamine', 'venuelocationsportscapacity', 'llanfairpwllgwyngyllgogerychwyrndrobwllllantysiliogogogoch', 'hooooooooooooooooooooooooooooo', 'generalfeldmarschalls', 'thislaughingguyrighthere', 'loooooooooooooooooooow', 'militärgeschichtliche', 'reinkarnationstherapie', 'reichssicherheitshauptamt', 'hahahhahhahahahahahahahahahahahahahahahahahahahahaha', 'desudesudesudesudesudesudesudesudesudesudesudesudesudesu', 'littleknowncyclingfacts', 'emmeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee', 'estatejobsclassifiedsshopbuy', 'opooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooo', 'tabtabtabinlinetagsfound', 'shuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuun', 'encyclopediadramatica', 'aladatransportesaereos', 'grrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr', 'faaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaagggggooooooooooooooooooootttttttttttttttttt', 'dedeeireidwedededijkkvir', 'shooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooowwwwwwwwwwwwwwwwwwwwwww', 'radiochecklistformerly', 'unitedtamworthnuneaton', 'jhedbejukqrfghukwerfguwe', 'ahahahahahahahahahahahahahahahahahahahahahaahhahahahahahahahahahahahahahah', 'fuuuuuuuuuuuuuucccccckkkkkkkkkkkkkkeeeeeeeeeeeer', 'stayfreewomenforindia', 'fffffffffffffffuuuuuuuuuuuuuuuuuuuuuuuccccccccccccckkkkkkkkkkkkkkkkkkk', 'nonsensefreesaveliytalk', 'ahahahaahhahahahahahahahahahahahahahahahahahahahahahahahahahahahahaha', 'disagreementviolations', 'zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz', 'hahhahhahahhhahhahahahha', 'cottonheadednittymuggin', 'morrisseyhotpressscreencap', 'gigowngnognronwoigwnoirowinowrioirwnorwoinrwoingroinrwoingroinoingwoingoinnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnw', 'interestparislondonnumber', 'fukerssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssss', 'nnnnnnnnnnnnooooooooooooooooowwwwwwwwwwwwwwwwww', 'hhhhhhhhhhhhhhaaaaaahaha', 'awwwwwwwwwwwwwwwwwwww', 'muuuuuuuuuuuuuuuuuuuuuuuuuuu', 'hmmmmmmmmmmmmmmmmmmmmmmmmmmmm', 'thefakesoundofprogress', 'mynameisthemasterofallofthefive', 'techniquesunsupervised', 'triphenylmethyllithium', 'yeeeeeeeeeeeeeeeeeeeeeeeeeeeeahhhhhhhhhh', 'balanceintergovernmental', 'mmmmmmmmmmmmmmmmmmmmmmmmmmk', 'letterlanguagecountry', 'ffffffffuuuuuuuuuuuucccccccccccccckkkkkkkkkkkkkkkk', 'northamnativeunverified', 'gaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa', 'dieeeeeeeeeeeeeeeeeeeee', 'deeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeerp', 'antidisestablishmentareanism', 'joshdiggydoggingrawhateverwhen', 'hahhahhahahahhahahahahahahahahaha', 'infrastructureintangible', 'entadminisierungsanträge', 'bookkeeperoftheoccult', 'zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz', 'markrevertedpagesasminor', 'myshoppinglistincludeseggs', 'paulskirchenverfassung', 'departuresdestinations', 'regiondateformatunited', 'justlettersandnumbers', 'uncategorizedcategories', 'dextromethamphetamine', 'teeeccccctooooniiiiiiiicccccc', 'pintobeanerniggermexican', 'iamzodyourzodeveryzod', 'hahahahahahahahahahahahaha', 'aaaaaaaahhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh', 'ooooooooooohhhhhhhhhh', 'neverguesswhathappene', 'yyyyyyyyyeeeeeeeeeeaaaaaaaaaahhhhhhhh', 'disambiguationsitation', 'hahahahahahhaahhahahahaha', 'hahahahahahahahahahahaha', 'hahahahahahahahahahahahahahaha', 'headadaaggggghhhhhhhh', 'bannnnnnnnnnnnnnnnnnnnnnnnnn', 'everrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrunder', 'requestforpageprotection', 'hahhahhahahahhahhahahahahhahahahahahaha', 'superflyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyy', 'ahahahahahahahahahahahahahahahahahahaha', 'whsssssssssssssssssssssssssssper', 'doooooooooooooooooooooooomed', 'juliannarosemauriello', 'shittttttttttttttttttttttttttttt', 'hahahahahahahahahaaha', 'wooooooooooooooooooooooooooow', 'kimdabelsteinpetersen', 'faaaaaaagggggggggggggyyyyyyyyyyyyyy', 'aaaannnnyyyywwwwhhhheeeerrrreeee', 'rovingpersonalityconstruct', 'zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz', 'plllllleeeeeaaaasssseeee', 'ppppppppppttttttttttthhhhhhhhhhhhhhhhhhhh', 'onlineambassadorprofile', 'pmlogocolorsmallframed', 'yyyyyyyyyyyyyyyyyooooooooooooouuuuuuuuu', 'ptptpthtphthpthhhhhhh', 'boooooooooooooooooooooooooooo', 'klsdjfhsdlkjfhsdjklfh', 'uuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuu', 'starcheerspeaksnewslostwarstalk', 'mwahahahahahahahahahahahahahahahahahahahaha', 'mmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmwmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmm', 'llllllloooooooooonnnngggggggg', 'hyyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyuyu', 'alllllllllllllllllllllllllllllll', 'tamworthkidderminster', 'cuntcuntcuntcuntcuntcuntcuntcuntcuntcuntcuntcuntcuntcuntcuntcuntcuntcuntcuntcuntcuntcuntcuntcuntcuntcuntcuntcuntcuntcuntcuntcuntcuntcuntcuntcuntcuntcuntcuntcuntcuntcuntcuntcuntcuntcunti', 'teamgpwotwotllgfgagdfpts', 'uncategorizedcategorie', 'brrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr', 'awwwwwwwwwwwwwwwwwwwwwwwwwwwwww', 'theunbelieveabletruth', 'maaaaaaaaaaaaaaaaaaaaaaad', 'yeeeeeeeeeeeeeeeeaaaaaaaaaaaaaahhhhhhhhhh', 'immortalhugantinormou', 'woooooooooooooooooooooooooooooooooooooooooooooooooo', 'nooooooooooooooooooooooooooooooooooooooooooo', 'hahahahahahahahahaaahahhaha', 'tabdavidgerardtabirate', 'awwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwww', 'hjyunnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnn', 'whhhhhhhhhhhhhyyyyyyyyyyyyyyyyyyyyy', 'methylenedioxymethamphetamine', 'littleknowncyclingfact', 'newsletterdepartments', 'faggotkikeniggermongo', 'hahahahhahahhahahahahahahahahahahahahahahahahahahahahahahaa', 'stildisgustinlidisabldostail', 'ifdsgvrfdgggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggggd', 'tiwhatevertheheckitis', 'otherusessubtopicalias', 'bongwarriorcongratualtion', 'pleasedontdeletemyedit', 'getthetenyearoldsoffhereplease', 'bennnnnnnnnnnnieeeeeeeeeee', 'cuntcuntcuntcuntcuntcuntcuntcuntcuntcuntcuntcuntcuntcuntcuntcuntcuntcuntcuntcuntcuntcuntcuntcuntcuntcuntcuntcuntcuntcuntcuntcu', 'pricewaterhousecooper', 'anywaaaaaaaaaaaaaaaaaaaaaaaaaaaaaay', 'floccinaucinihilipilification', 'timedarticlechangestabilisationmechanism', 'revolvingperonalconduct', 'uuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuu', 'jajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajajaja', 'hiineedrequestforcomment', 'zzzzzzzzzzzzzzzzzzzzzzzzzzzzzz', 'vandallllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll', 'muckanaghederdauhaulia', 'hahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahahaha', 'crapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcrapcr', 'reichssicherheitshauptam', 'yyyyyyyyyyyyyyybvgtfrrrrrbyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyy', 'pricewaterhousecoopers', 'soooooooooooooooooooooooooooooooooooooooooooooooooooooooooooo', 'hahahahahahhahahahahahah', 'photosfashionoscarsentertainmentlocalopinionslifestylemoneytech', 'agakhanpalacefrontview', 'markspeedypagesasminor', 'sdgbfhyufjfsjckfsijldxhltgfgn', 'errrrrrrryyyyydayyyyy', 'bonjourrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr', 'ssssssssstttttttaaaaaaaaaaayyyyyyyyy', 'girlforevermydarlingicon', 'nonononononjesusfuckingchristno', 'muheehahahahahahahahahah', 'ainaalfddarladarlingdearly', 'faaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaace', 'disproportionableness', 'aaaaaaahhhhhhhhhhhhhhhhhhhhhhhh', 'sooooooooooooooooooooooooooooo', 'woooooooooooooooooooooooooooooooooooooooooooo', 'arrrrrrrrrrrrrggggggggggggggghhhhhhhhhhhhhhhhhhh', 'randomstringofcharacters', 'hahahahahhahahahahahahahhahahahaha']\n"
     ]
    }
   ],
   "source": [
    "print([i for i in X_train_vocab if len(i) > 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# '''\n",
    "# CPU times: user 18min 49s, sys: 3.85 s, total: 18min 53s\n",
    "# Wall time: 18min 57s\n",
    "# '''\n",
    "# # get idf dict\n",
    "# idf_dict = idf(X_train['lemmas_less'].to_list(), vocabulary=X_train_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further reduce lemmas by min_length & max_length\n",
    "\n",
    "Exploration of corpus vocabulary suggests that lemmas of 2 or fewer characters are likely not very useful and can be removed to reduce features. \n",
    "\n",
    "Lemmas of longer than 20 characters are often run-on words (where spaces have been omitted). Although a few of them have words hidden within them that may be considered toxic, the rarity and non-standard format make them unlikely to be generalizable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 781 ms, sys: 2.12 s, total: 2.9 s\n",
      "Wall time: 10.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "min_l = 3\n",
    "max_l = 20\n",
    "\n",
    "X_train['lemmas_less'] = X_train['lemmas'].apply(lambda row: [lemma for lemma in row if len(lemma) >= min_l or len(lemma) <= max_l])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF*IDF out of the Box\n",
    "\n",
    "Resources:\n",
    "- [TfidfVectorizer Docs](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#sklearn.feature_extraction.text.TfidfVectorizer)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 33.4 s, sys: 1.17 s, total: 34.6 s\n",
      "Wall time: 34.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tfidf_sklearn = TfidfVectorizer(ngram_range = (1,3),\n",
    "                                min_df = 1)\n",
    "\n",
    "# return sparse matrix\n",
    "# join list into individual strings\n",
    "tfidf_values = tfidf_sklearn.fit_transform(X_train['lemmas_less'].apply(lambda x: \" \".join(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<106912x4089577 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 8002628 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.6 s, sys: 9.45 s, total: 22.1 s\n",
      "Wall time: 25.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "'''\n",
    "CPU times: user 11.9 s, sys: 8.27 s, total: 20.2 s\n",
    "Wall time: 23 s\n",
    "'''\n",
    "lemmas_less_tfidf = pd.DataFrame(tfidf_values.toarray(),\n",
    "                                 columns=tfidf_sklearn.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(106912, 4089577)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmas_less_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(106912,)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train['toxic'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.505664053836636"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sum(lemmas_less_tfidf['jerk'])\n",
    "\n",
    "# search_term = 'jerk'\n",
    "\n",
    "# # running this portion will crash the kernel\n",
    "# bool_mask = lemmas_less_tfidf.sort_values(search_term, ascending=False)[search_term][:10]\n",
    "# bool_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toxic: Random Forest Classifier\n",
    "\n",
    "Resources:\n",
    "- [Explanation of Warm Start for RFC (not what you may think)](https://stackoverflow.com/questions/42757892/how-to-use-warm-start/42763502)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_rfc = RandomForestClassifier(n_estimators=100,\n",
    "                                   max_depth = 10,\n",
    "                                   oob_score=True,\n",
    "                                   n_jobs=-1,\n",
    "                                   random_state=42,\n",
    "                                   warm_start=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.5 ms, sys: 80.4 ms, total: 92.9 ms\n",
      "Wall time: 31.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X = lemmas_less_tfidf\n",
    "y_toxic = y_train['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py:540: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py:545: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 33s, sys: 7min 15s, total: 9min 49s\n",
      "Wall time: 2min 55s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=10, n_estimators=1, n_jobs=-1, oob_score=True,\n",
       "                       random_state=42, warm_start=True)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "toxic_rfc.fit(X.iloc[:1000], y_toxic.iloc[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# naive_toxic = BernoulliNB\n",
    "# print(vect_X_train.shape)\n",
    "# print(y_train.shape)\n",
    "# print(X_train.shape)\n",
    "\n",
    "# vect_X_train.iloc[0]\n",
    "\n",
    "# naive_toxic.fit(vect_X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
