{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iaWoMJGfVwUB"
   },
   "source": [
    "# Toxic Text\n",
    "\n",
    "\n",
    "Detecting Insults in Social Commentary\n",
    "\n",
    "Data from Wikipedia \n",
    "\n",
    "Data Source:\n",
    "https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sMY7K_Yx9NVJ"
   },
   "source": [
    "# Resources & Articles\n",
    "\n",
    "Resources:\n",
    "- [Detecting Insults in Social Commentary Dataset On Kaggle](https://www.kaggle.com/c/detecting-insults-in-social-commentary/data) \n",
    "- [Cleaned Toxic Comments on Kaggle](https://www.kaggle.com/fizzbuzz/cleaned-toxic-comments)  \n",
    "- [Insult Sets](https://www.kaggle.com/rogier2012/insult-sets)  \n",
    "- [Wikipedia Talk Labels: Personal Attacks](https://datasetsearch.research.google.com/search?query=stalking%20text&docid=L2cvMTFqbnl5cWw0Xw%3D%3D) \n",
    "    -  [At Kaggle](https://datasetsearch.research.google.com/search?query=stalking%20text&docid=L2cvMTFqbnl5cWw0Xw%3D%3D)  \n",
    "- [Toxic Dataset](https://www.kaggle.com/ra2041/toxic-dataset)  \n",
    "- [Dataset for Mean Birds: Detecting Agression and Bullying on Twitter](https://zenodo.org/record/1184178) \n",
    "\n",
    "Articles: \n",
    "- [NLP AND MACHINE LEARNING TECHNIQUES TO DETECT\n",
    "ONLINE HARASSMENT...(has links to datasets)](https://dalspace.library.dal.ca/handle/10222/76331) \n",
    "- [Detecting Cyberbullying...](http://www.ijetsr.com/images/short_pdf/1517199597_1428-1435-oucip915_ijetsr.pdf) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XDRcsr5AZfQb"
   },
   "source": [
    "## Python Library Imports\n",
    "\n",
    "\n",
    "Resources:\n",
    "- [pool]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24997,
     "status": "ok",
     "timestamp": 1616376286409,
     "user": {
      "displayName": "Shawn Keech",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GicFJvHjGKSkP2elE1kc5WTSumC2FDDidD75Ssv0w=s64",
      "userId": "08670766559094446918"
     },
     "user_tz": 300
    },
    "id": "mQY7o6xDZhTe",
    "outputId": "73aee6d3-7edd-437f-eab4-36c67320b567"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "# nltk imports\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# scikit learn imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sLj78JbffsQ8"
   },
   "source": [
    "## Import Data to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic_2-1.pkl toxic_2-2.pkl toxic_2-3.pkl train.csv\n"
     ]
    }
   ],
   "source": [
    "! ls ../data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 26950,
     "status": "ok",
     "timestamp": 1616376288364,
     "user": {
      "displayName": "Shawn Keech",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GicFJvHjGKSkP2elE1kc5WTSumC2FDDidD75Ssv0w=s64",
      "userId": "08670766559094446918"
     },
     "user_tz": 300
    },
    "id": "UeyUW0XJRVGY"
   },
   "outputs": [],
   "source": [
    "# Load original from csv\n",
    "\n",
    "# path if using google colabs\n",
    "# path = \"gdrive/MyDrive/Colab Notebooks/capstone_exploration/data/toxic_comment_data/train.csv\"\n",
    "\n",
    "# local path\n",
    "path = '../data/train.csv'\n",
    "\n",
    "toxic_df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j2pbrgM5f0o6"
   },
   "source": [
    "# Basic Exploration\n",
    "\n",
    "Texts in the dataset are labeled by human users as either **Toxic** or **Not Toxic**. \n",
    "\n",
    "Toxic comments can be further categorized as displaying any combination of five subcategories. Toxic comments can belong to any of the subcategories, multiple subcategories, or no further subcategories.\n",
    "\n",
    "Subcategories:\n",
    "- Severely toxic\n",
    "- Obscene\n",
    "- Threat\n",
    "- Insult\n",
    "- Identity hate\n",
    "\n",
    "### Category Summary\n",
    "\n",
    "| Category            \t| Totals \t|\n",
    "|---------------------\t|-------:\t|\n",
    "| Not Toxic         \t| 144277 \t|\n",
    "| Toxic             \t|  15294 \t|\n",
    "| Toxic Subcategories \t|        \t|\n",
    "| Severely toxic      \t|   1595 \t|\n",
    "| Obscene             \t|   8449 \t|\n",
    "| Threat              \t|    478 \t|\n",
    "| Insult              \t|   7877 \t|\n",
    "| Identity hate       \t|   1405 \t|\n",
    "| Subcategories Total \t|  19804 \t|\n",
    "\n",
    "\n",
    "### Proportions\n",
    "\n",
    "About 10% of the comments in the dataset are considered Toxic.\n",
    "\n",
    "```\n",
    "Proportion of Not Toxic Comments in Dataset: 0.9041555169799024\n",
    "Proportion of Toxic Comments in Dataset: 0.09584448302009764\n",
    "```\n",
    "\n",
    "\n",
    "Resources:\n",
    "- [Table Generator](https://www.tablesgenerator.com/markdown_tables#)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26944,
     "status": "ok",
     "timestamp": 1616376288366,
     "user": {
      "displayName": "Shawn Keech",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GicFJvHjGKSkP2elE1kc5WTSumC2FDDidD75Ssv0w=s64",
      "userId": "08670766559094446918"
     },
     "user_tz": 300
    },
    "id": "453r8KHXRsZh",
    "outputId": "899de06c-d6f1-44d5-a249-676f78ffd696"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows labeled as Not Toxic: 144277\n",
      "Rows labeled as Toxic:      15294\n",
      "\n",
      "\n",
      "severe_toxic     1595\n",
      "obscene          8449\n",
      "threat            478\n",
      "insult           7877\n",
      "identity_hate    1405\n",
      "dtype: int64 \n",
      "\n",
      "total sub_toxic:            19804\n"
     ]
    }
   ],
   "source": [
    "# how many rows labeled as not toxic?\n",
    "not_toxic_count = toxic_df[toxic_df['toxic']==0].shape[0]\n",
    "print(f\"Rows labeled as Not Toxic: {not_toxic_count}\") # not toxic: (144277) \n",
    "\n",
    "# rows labeled toxic\n",
    "toxic_count = toxic_df[toxic_df['toxic']==1].shape[0]\n",
    "print(f\"Rows labeled as Toxic:      {toxic_count}\") # toxic: (15294)\n",
    "print('\\n')\n",
    "sub_toxic = toxic_df[['severe_toxic', 'obscene','threat','insult','identity_hate']].sum()\n",
    "\n",
    "print(sub_toxic, '\\n')\n",
    "print(f\"total sub_toxic:            {sub_toxic.sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26936,
     "status": "ok",
     "timestamp": 1616376288367,
     "user": {
      "displayName": "Shawn Keech",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GicFJvHjGKSkP2elE1kc5WTSumC2FDDidD75Ssv0w=s64",
      "userId": "08670766559094446918"
     },
     "user_tz": 300
    },
    "id": "7A-LuVRNnRfc",
    "outputId": "9caf5744-63cd-4cbb-e413-0e23a9f72106"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of Not Toxic Comments in Dataset: 0.9041555169799024\n",
      "Proportion of Toxic Comments in Dataset: 0.09584448302009764\n"
     ]
    }
   ],
   "source": [
    "# Proportions:\n",
    "total_rows = toxic_df.shape[0] # 159571\n",
    "\n",
    "# Not Toxic Proportion\n",
    "not_toxic_prop = not_toxic_count/total_rows # 0.9041555169799024\n",
    "print(f\"Proportion of Not Toxic Comments in Dataset: {not_toxic_prop}\")\n",
    "\n",
    "# Toxic Proportion\n",
    "toxic_prop = toxic_count/total_rows # 0.09584448302009764\n",
    "print(f\"Proportion of Toxic Comments in Dataset: {toxic_prop}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oxhq-7EOfpsB"
   },
   "source": [
    "# Drop 'id' Column From Full Dataset\n",
    "The id column is not really useful for our purposes, so we'll drop it from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 26935,
     "status": "ok",
     "timestamp": 1616376288367,
     "user": {
      "displayName": "Shawn Keech",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GicFJvHjGKSkP2elE1kc5WTSumC2FDDidD75Ssv0w=s64",
      "userId": "08670766559094446918"
     },
     "user_tz": 300
    },
    "id": "EXnAvoBef08q"
   },
   "outputs": [],
   "source": [
    "toxic_df.drop(columns='id', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gr3jPH3xfJkg"
   },
   "source": [
    "# Basic Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I1Md0mKVKwF9"
   },
   "source": [
    "Cleaning Functions:\n",
    "- convert interior quotes to all single quotes\n",
    "- strip any extraneous whitespace\n",
    "- strip any ip addresses\n",
    "- [strip url](https://stackoverflow.com/a/62729865)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 27061,
     "status": "ok",
     "timestamp": 1616376288495,
     "user": {
      "displayName": "Shawn Keech",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GicFJvHjGKSkP2elE1kc5WTSumC2FDDidD75Ssv0w=s64",
      "userId": "08670766559094446918"
     },
     "user_tz": 300
    },
    "id": "-yt0qUU9aTpR"
   },
   "outputs": [],
   "source": [
    "# Convert all interior quotes to single quotes\n",
    "\n",
    "def convert_interior_quotes(s):\n",
    "    '''\n",
    "    Arguments:\n",
    "        s = Series of strings\n",
    "            Takes a series of strings as an argument\n",
    "            converts all interior quotes in a string to single quotes\n",
    "    Returns: \n",
    "        Series of strings with interior quotes\n",
    "    '''\n",
    "    quotes_pattern = '[\"]+'\n",
    "    return s.str.replace(quotes_pattern, \"'\")\n",
    "\n",
    "def strip_ip(s):\n",
    "    '''\n",
    "    Arguments:\n",
    "        s = Series of strings\n",
    "            Takes a series of strings as an argument\n",
    "            removes any ip addresses\n",
    "    Returns: \n",
    "        Series of strings without ip addresses\n",
    "    '''\n",
    "    ip_pat = '(?:[0-9]{1,3}\\.){3}[0-9]{1,3}'\n",
    "    return s.str.replace(ip_pat, \"\")\n",
    "\n",
    "def strip_url(s):\n",
    "    '''\n",
    "    Arguments:\n",
    "        s = Series of strings\n",
    "            Takes a series of strings as an argument\n",
    "            removes any ip addresses\n",
    "    Returns: \n",
    "        Series of strings without url\n",
    "    '''\n",
    "    url_pat = 'https?:\\/\\/\\S*'\n",
    "    return s.str.replace(url_pat, \"\")\n",
    "\n",
    "def strip_whitespace(s):\n",
    "    '''\n",
    "    Arguments:\n",
    "        s = Series of strings\n",
    "            Takes a series of strings as an argument\n",
    "            removes extraneous whitespace\n",
    "    Returns: \n",
    "        Series of strings without extraneous whitespace\n",
    "    '''\n",
    "    \n",
    "    t = s.copy()\n",
    "    # remove whitespace from edge\n",
    "    t = t.str.strip()\n",
    "\n",
    "    # reduce interior whitespace to single space\n",
    "    t = t.str.replace('[\\s]+', ' ')\n",
    "\n",
    "    return t\n",
    "\n",
    "\n",
    "def remove_all_punct(s):\n",
    "    '''\n",
    "    Arguments:\n",
    "        s = Series of strings\n",
    "            Takes a series of strings as an argument\n",
    "            removes all punctuation\n",
    "    Returns: \n",
    "        Series of strings with no punctuation\n",
    "    '''\n",
    "    not_alpha_pattern = '[^A-Za-z\\s]'\n",
    "    return s.str.replace(not_alpha_pattern, \"\")\n",
    "\n",
    "def tidy_series(s):\n",
    "    '''\n",
    "    returns tidied series\n",
    "    '''\n",
    "    # copy series\n",
    "    t = s.copy()\n",
    "\n",
    "    # call individual functions\n",
    "    t = convert_interior_quotes(t)\n",
    "    t = strip_whitespace(t)\n",
    "    t = strip_ip(t)\n",
    "    t = strip_url(t)\n",
    "\n",
    "    return t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E6FBNzeFz_Z3"
   },
   "source": [
    "## Apply Basic Cleaning to Full Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 35569,
     "status": "ok",
     "timestamp": 1616376297005,
     "user": {
      "displayName": "Shawn Keech",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GicFJvHjGKSkP2elE1kc5WTSumC2FDDidD75Ssv0w=s64",
      "userId": "08670766559094446918"
     },
     "user_tz": 300
    },
    "id": "aIrrLup_eB8n"
   },
   "outputs": [],
   "source": [
    "# tidy comment_text\n",
    "toxic_df['comment_text'] = tidy_series(toxic_df['comment_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Explanation Why the edits made under my userna...\n",
       "1    D'aww! He matches this background colour I'm s...\n",
       "2    Hey man, I'm really not trying to edit war. It...\n",
       "3    ' More I can't make any real suggestions on im...\n",
       "4    You, sir, are my hero. Any chance you remember...\n",
       "Name: comment_text, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic_df['comment_text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HfuWNkaLxJyq"
   },
   "source": [
    "# Basic Feature Engineering\n",
    "\n",
    "There are a few features that are not obvious in the original dataset that may be useful for prediction and classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RL3Pg8V2kV9o"
   },
   "source": [
    "Resource:  \n",
    "- [running pandas operations in parallel](http://www.racketracer.com/2016/07/06/pandas-in-parallel/)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 221,
     "status": "ok",
     "timestamp": 1616377214101,
     "user": {
      "displayName": "Shawn Keech",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GicFJvHjGKSkP2elE1kc5WTSumC2FDDidD75Ssv0w=s64",
      "userId": "08670766559094446918"
     },
     "user_tz": 300
    },
    "id": "18A-7gyNjUEF"
   },
   "outputs": [],
   "source": [
    "# # parallelize dataframe\n",
    "\n",
    "from multiprocessing import Pool\n",
    "# import multiprocessing\n",
    "\n",
    "# multiprocessing.cpu_count() # 2 for colabs\n",
    "# num_partitions = 100\n",
    "# num_cores = 4\n",
    "\n",
    "def parallelize_dataframe(df, func, num_cores=2, num_partitions=100):\n",
    "    df_split = np.array_split(df, num_partitions)\n",
    "    pool = Pool(num_cores)\n",
    "    df = pd.concat(pool.map(func, df_split))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2hD5ZPqZ1g2E"
   },
   "source": [
    "## Proportion of All-Caps Type\n",
    "\n",
    "In many circles, typing in all caps is considered a way to indicate yelling. Before changing the initial text, we'll record the proportion of upper case letters to the total number of alphabetical characters. \n",
    "\n",
    "PossibleConfounds:\n",
    "- [People with dislexia occasionally choose all-caps as an accomodataion](https://www.readandspell.com/us/writing-in-all-caps)  \n",
    "- Quoted all-caps text\n",
    "    - not counting quoted and block quoted text may help here.\n",
    "- Text referencing all-caps acronymns\n",
    "- Programming language conventions\n",
    "    - e.g. SQL syntax typically inlcudes all-caps reserved words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dqfBTb7-JF2k"
   },
   "source": [
    "### Custom Function: uppercase_proportion_column(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 89,
     "status": "aborted",
     "timestamp": 1616376571553,
     "user": {
      "displayName": "Shawn Keech",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GicFJvHjGKSkP2elE1kc5WTSumC2FDDidD75Ssv0w=s64",
      "userId": "08670766559094446918"
     },
     "user_tz": 300
    },
    "id": "4z1KnAdZ0ApC"
   },
   "outputs": [],
   "source": [
    "def uppercase_proportion_column(s):\n",
    "    '''\n",
    "    given a pandas Series:\n",
    "        containing rows of strings\n",
    "    returns: a series of floats representing\n",
    "        the percentage of capital letters vs total alpha chars\n",
    "        in provided strings\n",
    "    '''\n",
    "    import re # dependent on re\n",
    "\n",
    "    uc_pattern = '[A-Z]'\n",
    "    alpha_pattern = '[A-Za-z]'\n",
    "\n",
    "    cap_count = s.str.findall(uc_pattern).str.len()\n",
    "    # print(cap_count)\n",
    "\n",
    "    alpha_char_count = s.str.findall(alpha_pattern).str.len()\n",
    "    # print(alpha_char_count)\n",
    "\n",
    "    uc_proportion = cap_count / alpha_char_count\n",
    "    # print(uc_proportion)\n",
    "\n",
    "    return uc_proportion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sF18XirY0QoT"
   },
   "source": [
    "## Apply Custom Features to Full Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult',\n",
       "       'identity_hate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 72,
     "status": "aborted",
     "timestamp": 1616376571555,
     "user": {
      "displayName": "Shawn Keech",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GicFJvHjGKSkP2elE1kc5WTSumC2FDDidD75Ssv0w=s64",
      "userId": "08670766559094446918"
     },
     "user_tz": 300
    },
    "id": "6bOQnYDswWCM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.74 s, sys: 806 ms, total: 10.5 s\n",
      "Wall time: 9.92 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['comment_text', 'uppercase_proportion', 'toxic', 'severe_toxic',\n",
       "       'obscene', 'threat', 'insult', 'identity_hate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# create uppercase_proportion column\n",
    "toxic_df.insert(1, 'uppercase_proportion', uppercase_proportion_column(toxic_df['comment_text']))\n",
    "toxic_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uppercase Proportion mean:           0.06970968433852934\n",
      "Uppercase Proportion mean not toxic: 0.06073052868635834\n",
      "Uppercase Proportion mean toxic:     0.15440166285616988\n"
     ]
    }
   ],
   "source": [
    "mean_all = toxic_df['uppercase_proportion'].mean()\n",
    "mean_not_toxic = toxic_df['uppercase_proportion'][toxic_df['toxic']==0].mean()\n",
    "mean_toxic = toxic_df['uppercase_proportion'][toxic_df['toxic']==1].mean()\n",
    "\n",
    "'''\n",
    "Uppercase Proportion mean:           0.06970968433852934\n",
    "Uppercase Proportion mean not toxic: 0.06073052868635834\n",
    "Uppercase Proportion mean toxic:     0.15440166285616988\n",
    "'''\n",
    "\n",
    "print(f\"Uppercase Proportion mean:           {mean_all}\")\n",
    "print(f\"Uppercase Proportion mean not toxic: {mean_not_toxic}\")\n",
    "print(f\"Uppercase Proportion mean toxic:     {mean_toxic}\")\n",
    "# uppercase proportion for toxic comments is over twice that of not toxic comments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Basic Columns As Pickle File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 87.8 ms, sys: 68.3 ms, total: 156 ms\n",
      "Wall time: 214 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "'''\n",
    "CPU times: user 87.8 ms, sys: 68.3 ms, total: 156 ms\n",
    "Wall time: 214 ms\n",
    "'''\n",
    "# Pickle basic\n",
    "toxic_df.to_pickle(\"../data/toxic_basic.pkl\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOCF+j+08tL5QgwPVB141nM",
   "collapsed_sections": [],
   "name": "toxic_text.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
