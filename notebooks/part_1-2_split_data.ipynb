{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iaWoMJGfVwUB"
   },
   "source": [
    "# Detecting and Classifying Toxic Comments\n",
    "# Part 1-2: Split the Data\n",
    "\n",
    "We'll first split our data in to a training and a holdout group. We'll do a stratified split with the training data in order to maintain the  Not Toxic to Toxic text ratio of roughly 9:1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XDRcsr5AZfQb",
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "## Python Library Imports\n",
    "\n",
    "\n",
    "Resources:\n",
    "- [pool]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24997,
     "status": "ok",
     "timestamp": 1616376286409,
     "user": {
      "displayName": "Shawn Keech",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GicFJvHjGKSkP2elE1kc5WTSumC2FDDidD75Ssv0w=s64",
      "userId": "08670766559094446918"
     },
     "user_tz": 300
    },
    "id": "mQY7o6xDZhTe",
    "outputId": "73aee6d3-7edd-437f-eab4-36c67320b567",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter\n",
    "import re\n",
    "import random\n",
    "\n",
    "# scikit learn imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# tqdm & time\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xTRgdYMCHaHD",
    "tags": []
   },
   "source": [
    "## spaCy Setup & Imports\n",
    "\n",
    "As mentioned previously, we'll be using spaCy version 2.3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "============================== Info about spaCy ==============================\u001b[0m\n",
      "\n",
      "spaCy version    2.3.5                         \n",
      "Location         /opt/anaconda3/lib/python3.7/site-packages/spacy\n",
      "Platform         Darwin-20.3.0-x86_64-i386-64bit\n",
      "Python version   3.7.6                         \n",
      "Models                                         \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # check version\n",
    "! python -m spacy info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spaCy Imports\n",
    "import spacy\n",
    "\n",
    "from spacy.lang.en import English\n",
    "spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "from spacy.util import minibatch, compounding\n",
    "from spacy import displacy\n",
    "from spacy.tokens import Doc\n",
    "\n",
    "from spacy.scorer import Scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data from toxic_basic Pickle File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 114 ms, sys: 83.9 ms, total: 197 ms\n",
      "Wall time: 213 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "'''\n",
    "last load time:\n",
    "\n",
    "CPU times: user 67 ms, sys: 46.7 ms, total: 114 ms\n",
    "Wall time: 114 ms\n",
    "'''\n",
    "\n",
    "# load toxic_basic pickle into dataframe\n",
    "path_toxic_basic = \"../data/toxic_basic.pkl\"\n",
    "\n",
    "toxic_df = pd.read_pickle(path_toxic_basic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 8 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   comment_text          159571 non-null  object \n",
      " 1   uppercase_proportion  159548 non-null  float64\n",
      " 2   toxic                 159571 non-null  int64  \n",
      " 3   severe_toxic          159571 non-null  int64  \n",
      " 4   obscene               159571 non-null  int64  \n",
      " 5   threat                159571 non-null  int64  \n",
      " 6   insult                159571 non-null  int64  \n",
      " 7   identity_hate         159571 non-null  int64  \n",
      "dtypes: float64(1), int64(6), object(1)\n",
      "memory usage: 9.7+ MB\n"
     ]
    }
   ],
   "source": [
    "toxic_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert training text and training outcomes into a list of tuples\n",
    "\n",
    "toxic_df[\"tuples\"] = toxic_df.apply(lambda row: (row['comment_text'], row['toxic']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"Explanation Why the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.\",\n",
       " 0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic_df['tuples'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B_qN8SvmysyP"
   },
   "source": [
    "# Simple Train Test Split\n",
    "\n",
    "As our process should first determine whether the text is toxic or not toxic, we'll make a simplified stratified train test split, ensuring our balance of toxic and non toxic rows are proportionally distributed.\n",
    "\n",
    "For now, we won't be too concerned with the proportion of sub-categories, as our first step will be to filter not toxic from toxic, then run parallel operations for each toxic sub-category, as toxic sub-categories are not mutually exclusive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vTncCacxukC-"
   },
   "source": [
    "## Stratified Split maintaining ratio of toxic to not toxic texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['comment_text', 'uppercase_proportion', 'toxic', 'severe_toxic',\n",
       "       'obscene', 'threat', 'insult', 'identity_hate', 'tuples'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check current columns\n",
    "toxic_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 67,
     "status": "aborted",
     "timestamp": 1616376571555,
     "user": {
      "displayName": "Shawn Keech",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GicFJvHjGKSkP2elE1kc5WTSumC2FDDidD75Ssv0w=s64",
      "userId": "08670766559094446918"
     },
     "user_tz": 300
    },
    "id": "-3rJS3ZRuipN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X columns: Index(['comment_text', 'uppercase_proportion'], dtype='object')\n",
      "y columns:Index(['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate',\n",
      "       'tuples'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# split df into X(independent) and y(depenendent) groups\n",
    "ind_cols = ['comment_text', 'uppercase_proportion']\n",
    "\n",
    "X = toxic_df[ind_cols]\n",
    "y = toxic_df.drop(columns=ind_cols)\n",
    "\n",
    "print(f\"X columns: {X.columns}\\ny columns:{y.columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 63,
     "status": "aborted",
     "timestamp": 1616376571556,
     "user": {
      "displayName": "Shawn Keech",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GicFJvHjGKSkP2elE1kc5WTSumC2FDDidD75Ssv0w=s64",
      "userId": "08670766559094446918"
     },
     "user_tz": 300
    },
    "id": "WJZnb8Pl1Stk"
   },
   "outputs": [],
   "source": [
    "# Train Test Split. Stratified on y['toxic']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.33, \n",
    "                                                    random_state=42, \n",
    "                                                    stratify=y['toxic'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stratified K Fold\n",
    "\n",
    "- [SKF docs](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html#)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedKFold(n_splits=3, random_state=42, shuffle=True)\n"
     ]
    }
   ],
   "source": [
    "tiny_df = toxic_df.sample(20)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3,\n",
    "                      random_state=42,\n",
    "                      shuffle=True)\n",
    "print(skf)\n",
    "\n",
    "skf.get_n_splits(X_train['comment_text'], y_train['toxic'])\n",
    "\n",
    "# for tr_in, test_in in skf.split(toxic['comment_text'], toxic['toxic']):\n",
    "#     print(tr_in, test_in)\n",
    "\n",
    "\n",
    "train_indx, test_indx = next(skf.split(toxic_df['comment_text'], toxic_df['toxic']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "egZZdQA3hS2u"
   },
   "source": [
    "# spaCy\n",
    "\n",
    "Let's try out spaCy, a nlp processing library!\n",
    "\n",
    "- https://course.spacy.io/en/chapter1\n",
    "- [text classification with spaCy](https://www.dataquest.io/blog/tutorial-text-classification-in-python-using-spacy/) \n",
    "- [customized list of stopwords](https://spacy.io/usage/linguistic-features#stop-words)  \n",
    "- [Split Series into list of sentences](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.cat.html)  \n",
    "- [contractions](https://theslaps.medium.com/cant-stand-don-t-want-contractions-with-spacy-39715cac2ebb)  \n",
    "\n",
    "\n",
    "- [v2.spacy.io](https://v2.spacy.io/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try new, blank spaCy model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d4D7rYTjHXYY"
   },
   "source": [
    "## Establish spaCy Pipeline\n",
    "\n",
    "\"spaCy's components are supervised models for text annotations, meaning hey can only learn to reproduce examples, not guess new labels from raw text.\"\n",
    "\n",
    "Resources:\n",
    "- [for emojis](https://spacy.io/universe/project/spacymoji)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code is modified from tutorial here:\n",
    "\n",
    "Resource:\n",
    "https://www.machinelearningplus.com/nlp/custom-text-classification-spacy/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resources\n",
    "- [spaCy docs: scorer](https://spacy.io/api/scorer)  \n",
    "\n",
    "- [F-Score](https://en.wikipedia.org/wiki/F-score)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# nlp = spacy.blank('en')\n",
    "import en_core_web_lg\n",
    "nlp = en_core_web_lg.load()\n",
    "\n",
    "# Provide scoring pipeline\n",
    "scorer = Scorer(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tagger', 'parser', 'ner']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tagger = nlp.create_pipe('tagger')\n",
    "textcat = nlp.create_pipe('textcat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp.add_pipe(tagger)\n",
    "nlp.add_pipe(textcat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textcat.add_label(\"TOXIC\")\n",
    "textcat.add_label(\"NOT TOXIC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tagger', 'parser', 'ner', 'textcat']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I left off here!!!\n",
    "\n",
    "https://v2.spacy.io/usage/processing-pipelines#pipelines\n",
    "https://v2.spacy.io/usage/processing-pipelines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from spacy.tokens import Doc\n",
    "# from spacy.training import Example\n",
    "\n",
    "\n",
    "def txt_and_cat(txt_series, cat_series):\n",
    "        \n",
    "    # convert each series or series slice to list\n",
    "    t = txt_series.tolist()\n",
    "    c = cat_series.tolist()\n",
    "    \n",
    "    # format categories\n",
    "    c = [{\"TOXIC\": bool(y), \"NOT TOXIC\": not bool(y)} for y in c]\n",
    "    c = [{'cats': i} for i in c]\n",
    "    \n",
    "    docs = list(zip(t, c))\n",
    "    \n",
    "    return docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Article for v3](https://medium.com/analytics-vidhya/building-a-text-classifier-with-spacy-3-0-dd16e9979a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ! ls ../models/base_config.cfg\n",
    "# ! python -m spacy init fill-config ../models/base_config.cfg config.cfg --diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! python -m spacy validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# formatting list of tuples for spacy training\n",
    "txt = toxic_df['comment_text'][train_indx]\n",
    "cat = toxic_df['toxic'][train_indx]\n",
    "\n",
    "train_docs = txt_and_cat(txt, cat)\n",
    "\n",
    "test_txt = toxic_df['comment_text'][test_indx]\n",
    "test_cat = toxic_df['toxic'][test_indx]\n",
    "\n",
    "test_docs = txt_and_cat(test_txt, test_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106380 53191\n",
      "[(\"Explanation Why the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.\", {'cats': {'TOXIC': False, 'NOT TOXIC': True}}), (\"D'aww! He matches this background colour I'm seemingly stuck with. Thanks. (talk) 21:51, January 11, 2016 (UTC)\", {'cats': {'TOXIC': False, 'NOT TOXIC': True}}), (\"Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.\", {'cats': {'TOXIC': False, 'NOT TOXIC': True}}), (\"' More I can't make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of 'types of accidents' -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know. There appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up. It's listed in the relevant form eg Wikipedia:Good_article_nominations#Transport '\", {'cats': {'TOXIC': False, 'NOT TOXIC': True}}), (\"' Congratulations from me as well, use the tools well. · talk '\", {'cats': {'TOXIC': False, 'NOT TOXIC': True}})]\n"
     ]
    }
   ],
   "source": [
    "# this should be the correct format expected by the trainer\n",
    "print(len(train_docs), len(test_docs))\n",
    "\n",
    "# print(train_docs[0][1])\n",
    "\n",
    "print([i for i in train_docs[:5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_txt_lst = [i[0] for i in test_docs]\n",
    "test_cat_lst = [i[1] for i in test_docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.machinelearningplus.com/nlp/custom-text-classification-spacy\n",
    "\n",
    "# Not providing proper scoring..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(tokenizer, textcat, texts, cats):\n",
    "    docs = (tokenizer(text) for text in texts)\n",
    "    tp = 0.0  # True positives\n",
    "    fp = 1e-8  # False positives\n",
    "    fn = 1e-8  # False negatives\n",
    "    tn = 0.0  # True negatives\n",
    "    for i, doc in enumerate(textcat.pipe(docs)):\n",
    "        gold = cats[i]\n",
    "        for label, score in doc.cats.items():\n",
    "            if label not in gold:\n",
    "                continue\n",
    "            if label == \"TOXIC\":\n",
    "                continue\n",
    "            if score >= 0.5 and gold[label] >= 0.5:\n",
    "                tp += 1.0\n",
    "            elif score >= 0.5 and gold[label] < 0.5:\n",
    "                fp += 1.0\n",
    "            elif score < 0.5 and gold[label] < 0.5:\n",
    "                tn += 1\n",
    "            elif score < 0.5 and gold[label] >= 0.5:\n",
    "                fn += 1\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    if (precision + recall) == 0:\n",
    "        f_score = 0.0\n",
    "    else:\n",
    "        f_score = 2 * (precision * recall) / (precision + recall)\n",
    "    return {\"textcat_p\": precision, \"textcat_r\": recall, \"textcat_f\": f_score}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_docs[:1000]\n",
    "dev_texts = test_txt_lst[:1000]\n",
    "dev_cats = test_cat_lst[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "LOSS \t  P  \t  R  \t  F  \n",
      "3.391\t0.000\t0.000\t0.000\n",
      "2.828\t0.000\t0.000\t0.000\n",
      "2.170\t0.000\t0.000\t0.000\n",
      "1.448\t0.000\t0.000\t0.000\n",
      "1.198\t0.000\t0.000\t0.000\n",
      "0.724\t0.000\t0.000\t0.000\n",
      "0.427\t0.000\t0.000\t0.000\n",
      "0.219\t0.000\t0.000\t0.000\n",
      "0.230\t0.000\t0.000\t0.000\n",
      "0.240\t0.000\t0.000\t0.000\n"
     ]
    }
   ],
   "source": [
    "from spacy.util import minibatch, compounding\n",
    "\n",
    "\n",
    "#(\"Number of training iterations\", \"n\", int))\n",
    "n_iter=10\n",
    "\n",
    "# Disabling other components\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'textcat']\n",
    "with nlp.disable_pipes(*other_pipes):  \n",
    "    optimizer = nlp.begin_training()\n",
    "\n",
    "    print(\"Training the model...\")\n",
    "    print('{:^5}\\t{:^5}\\t{:^5}\\t{:^5}'.format('LOSS', 'P', 'R', 'F'))\n",
    "\n",
    "    # Performing training\n",
    "    for i in range(n_iter):\n",
    "        losses = {}\n",
    "        batches = minibatch(train_data, size=compounding(4., 32., 1.001))\n",
    "        for batch in batches:\n",
    "            texts, annotations = zip(*batch)\n",
    "            nlp.update(texts, annotations, sgd=optimizer, drop=0.2,\n",
    "                       losses=losses)\n",
    "\n",
    "      # Calling the evaluate() function and printing the scores\n",
    "        with textcat.model.use_params(optimizer.averages):\n",
    "            scores = evaluate(nlp.tokenizer, textcat, dev_texts, dev_cats)\n",
    "        print('{0:.3f}\\t{1:.3f}\\t{2:.3f}\\t{3:.3f}'  \n",
    "              .format(losses['textcat'], scores['textcat_p'],\n",
    "                      scores['textcat_r'], scores['textcat_f']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'TOXIC': 0.9999545812606812, 'NOT TOXIC': 0.002241710666567087}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing the model\n",
    "# txt = toxic_df['comment_text'][train_indx]\n",
    "# cat = toxic_df['toxic'][train_indx]\n",
    "\n",
    "# train_docs = txt_and_cat(txt, cat)\n",
    "\n",
    "# test_txt = toxic_df['comment_text'][test_indx]\n",
    "# test_cat = toxic_df['toxic'][test_indx]\n",
    "\n",
    "# test_docs = txt_and_cat(test_txt, test_cat)\n",
    "\n",
    "test_text = test_txt\n",
    "\n",
    "print(test_text[6])\n",
    "\n",
    "\n",
    "doc=nlp(test_text[6])\n",
    "doc.cats "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[expanding contractions](https://gist.github.com/widiger-anna/deefac010da426911381c118a97fc23f) \n",
    "[contractions](https://theslaps.medium.com/cant-stand-don-t-want-contractions-with-spacy-39715cac2ebb)  \n",
    "\n",
    "\n",
    "[text wrangling](https://www.kdnuggets.com/2018/08/practitioners-guide-processing-understanding-text-2.html)  \n",
    "\n",
    "\n",
    "[nlp nltk vs spacy](https://www.activestate.com/blog/natural-language-processing-nltk-vs-spacy/)  \n",
    "\n",
    "[pytorch](https://pytorch.org/https://pytorch.org/)  \n",
    "\n",
    "[text classification in python with spacy (try this one!)](https://www.dataquest.io/blog/tutorial-text-classification-in-python-using-spacy/https://www.dataquest.io/blog/tutorial-text-classification-in-python-using-spacy/)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/machine-learning-nlp-text-classification-using-scikit-learn-python-and-nltk-c52b92a7c73a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOCF+j+08tL5QgwPVB141nM",
   "collapsed_sections": [],
   "name": "toxic_text.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
