{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iaWoMJGfVwUB"
   },
   "source": [
    "# Detecting and Classifying Toxic Comments\n",
    "# Part 2-3: spaCy Multi-Category Test\n",
    "\n",
    "Testing multiple, non-mutually exclusive categories with 1 instead of True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XDRcsr5AZfQb",
    "tags": []
   },
   "source": [
    "## Python Library Imports\n",
    "\n",
    "\n",
    "Resources:\n",
    "- [pool]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24997,
     "status": "ok",
     "timestamp": 1616376286409,
     "user": {
      "displayName": "Shawn Keech",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GicFJvHjGKSkP2elE1kc5WTSumC2FDDidD75Ssv0w=s64",
      "userId": "08670766559094446918"
     },
     "user_tz": 300
    },
    "id": "mQY7o6xDZhTe",
    "outputId": "73aee6d3-7edd-437f-eab4-36c67320b567",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter\n",
    "import re\n",
    "import random\n",
    "\n",
    "# scikit learn imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# # tqdm & time\n",
    "# from tqdm.auto import tqdm\n",
    "# import time\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xTRgdYMCHaHD",
    "tags": []
   },
   "source": [
    "## spaCy Setup & Imports\n",
    "\n",
    "As mentioned previously, we'll be using spaCy version 2.3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "============================== Info about spaCy ==============================\u001b[0m\n",
      "\n",
      "spaCy version    2.3.5                         \n",
      "Location         /opt/anaconda3/lib/python3.7/site-packages/spacy\n",
      "Platform         Darwin-20.3.0-x86_64-i386-64bit\n",
      "Python version   3.7.6                         \n",
      "Models                                         \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # check version\n",
    "! python -m spacy info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spaCy Imports\n",
    "import spacy\n",
    "\n",
    "from spacy.lang.en import English\n",
    "spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "from spacy.util import minibatch, compounding\n",
    "from spacy import displacy\n",
    "from spacy.tokens import Doc\n",
    "\n",
    "from spacy.scorer import Scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data from toxic_basic Pickle File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 72.5 ms, sys: 55.7 ms, total: 128 ms\n",
      "Wall time: 136 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "'''\n",
    "last load time:\n",
    "\n",
    "CPU times: user 67 ms, sys: 46.7 ms, total: 114 ms\n",
    "Wall time: 114 ms\n",
    "'''\n",
    "\n",
    "# load toxic_basic pickle into dataframe\n",
    "path_toxic_basic = \"../data/toxic_basic.pkl\"\n",
    "\n",
    "toxic_df = pd.read_pickle(path_toxic_basic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 8 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   comment_text          159571 non-null  object \n",
      " 1   uppercase_proportion  159548 non-null  float64\n",
      " 2   toxic                 159571 non-null  int64  \n",
      " 3   severe_toxic          159571 non-null  int64  \n",
      " 4   obscene               159571 non-null  int64  \n",
      " 5   threat                159571 non-null  int64  \n",
      " 6   insult                159571 non-null  int64  \n",
      " 7   identity_hate         159571 non-null  int64  \n",
      "dtypes: float64(1), int64(6), object(1)\n",
      "memory usage: 9.7+ MB\n"
     ]
    }
   ],
   "source": [
    "toxic_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing tuples here...\n",
    "# Convert training text and training outcomes into a list of tuples\n",
    "\n",
    "# toxic_df[\"tuples\"] = toxic_df.apply(lambda row: (row['comment_text'], row['toxic']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# toxic_df['tuples'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B_qN8SvmysyP"
   },
   "source": [
    "# Simple Train Test Split\n",
    "\n",
    "As our process should first determine whether the text is toxic or not toxic, we'll make a simplified stratified train test split, ensuring our balance of toxic and non toxic rows are proportionally distributed.\n",
    "\n",
    "For now, we won't be too concerned with the proportion of sub-categories, as our first step will be to filter not toxic from toxic, then run parallel operations for each toxic sub-category, as toxic sub-categories are not mutually exclusive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vTncCacxukC-"
   },
   "source": [
    "## Stratified Split maintaining ratio of toxic to not toxic texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['comment_text', 'uppercase_proportion', 'toxic', 'severe_toxic',\n",
       "       'obscene', 'threat', 'insult', 'identity_hate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check current columns\n",
    "toxic_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 67,
     "status": "aborted",
     "timestamp": 1616376571555,
     "user": {
      "displayName": "Shawn Keech",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GicFJvHjGKSkP2elE1kc5WTSumC2FDDidD75Ssv0w=s64",
      "userId": "08670766559094446918"
     },
     "user_tz": 300
    },
    "id": "-3rJS3ZRuipN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X columns: Index(['comment_text', 'uppercase_proportion'], dtype='object')\n",
      "y columns:Index(['toxic', 'severe_toxic', 'obscene', 'threat', 'insult',\n",
      "       'identity_hate'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# split df into X(independent) and y(depenendent) groups\n",
    "ind_cols = ['comment_text', 'uppercase_proportion']\n",
    "\n",
    "X = toxic_df[ind_cols]\n",
    "y = toxic_df.drop(columns=ind_cols)\n",
    "\n",
    "print(f\"X columns: {X.columns}\\ny columns:{y.columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 63,
     "status": "aborted",
     "timestamp": 1616376571556,
     "user": {
      "displayName": "Shawn Keech",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GicFJvHjGKSkP2elE1kc5WTSumC2FDDidD75Ssv0w=s64",
      "userId": "08670766559094446918"
     },
     "user_tz": 300
    },
    "id": "WJZnb8Pl1Stk"
   },
   "outputs": [],
   "source": [
    "# Train Test Split. Stratified on y['toxic']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.33, \n",
    "                                                    random_state=42, \n",
    "                                                    stratify=y['toxic'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stratified K Fold\n",
    "\n",
    "- [SKF docs](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html#)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tiny_df = toxic_df.sample(20)\n",
    "\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# skf = StratifiedKFold(n_splits=3,\n",
    "#                       random_state=42,\n",
    "#                       shuffle=True)\n",
    "# print(skf)\n",
    "\n",
    "# skf.get_n_splits(X_train['comment_text'],\n",
    "#                  y_train[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']])\n",
    "\n",
    "# train_indx, test_indx = next(skf.split(toxic_df['comment_text'], toxic_df[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "egZZdQA3hS2u"
   },
   "source": [
    "# spaCy\n",
    "\n",
    "Let's try out spaCy, a nlp processing library!\n",
    "\n",
    "- https://course.spacy.io/en/chapter1\n",
    "- [text classification with spaCy](https://www.dataquest.io/blog/tutorial-text-classification-in-python-using-spacy/) \n",
    "- [customized list of stopwords](https://spacy.io/usage/linguistic-features#stop-words)  \n",
    "- [Split Series into list of sentences](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.cat.html)  \n",
    "- [contractions](https://theslaps.medium.com/cant-stand-don-t-want-contractions-with-spacy-39715cac2ebb)  \n",
    "\n",
    "\n",
    "- [v2.spacy.io](https://v2.spacy.io/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train spaCy Model for Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d4D7rYTjHXYY",
    "tags": []
   },
   "source": [
    "## Establish spaCy Pipeline\n",
    "\n",
    "\"spaCy's components are supervised models for text annotations, meaning that they can only learn to reproduce examples, not guess new labels from raw text.\"\n",
    "\n",
    "By default, spaCy's text categorizer is a simple convolutional neural network.\n",
    "\n",
    "Resources:\n",
    "- [for emojis](https://spacy.io/universe/project/spacymoji)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code is modified from tutorial here:\n",
    "\n",
    "Resource:\n",
    "https://www.machinelearningplus.com/nlp/custom-text-classification-spacy/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resources\n",
    "- [spaCy docs: scorer](https://spacy.io/api/scorer)  \n",
    "\n",
    "- [F-Score](https://en.wikipedia.org/wiki/F-score)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## if the model is not yet locally available\n",
    "# ! python -m spacy download en_core_web_lg\n",
    "\n",
    "import en_core_web_lg\n",
    "nlp = en_core_web_lg.load()\n",
    "\n",
    "# Provide scoring pipeline\n",
    "scorer = Scorer(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tagger', 'parser', 'ner']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tagger = nlp.create_pipe('tagger')\n",
    "textcat = nlp.create_pipe('textcat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp.add_pipe(tagger)\n",
    "nlp.add_pipe(textcat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# textcat.add_label(\"TOXIC\")\n",
    "# textcat.add_label(\"SEVERE_TOXIC\")\n",
    "# textcat.add_label(\"OBSCENE\")\n",
    "# textcat.add_label(\"THREAT\")\n",
    "# textcat.add_label(\"INSULT\")\n",
    "# textcat.add_label(\"IDENTITY_HATE\")\n",
    "# # textcat.add_label(\"NOT TOXIC\")\n",
    "\n",
    "def add_labels_helper(s):\n",
    "    '''\n",
    "    takes dataframe or series, \n",
    "    unpacks col labels and adds each as label to textcat\n",
    "        formatted as uppercase\n",
    "    '''\n",
    "    \n",
    "    for col in s.columns:\n",
    "        print(col)\n",
    "        textcat.add_label(col.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic\n",
      "severe_toxic\n",
      "obscene\n",
      "threat\n",
      "insult\n",
      "identity_hate\n"
     ]
    }
   ],
   "source": [
    "add_labels_helper(y_train)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tagger', 'parser', 'ner', 'textcat']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('TOXIC', 'SEVERE_TOXIC', 'OBSCENE', 'THREAT', 'INSULT', 'IDENTITY_HATE')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textcat.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I left off here!!!\n",
    "\n",
    "https://v2.spacy.io/usage/processing-pipelines#pipelines\n",
    "https://v2.spacy.io/usage/processing-pipelines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[zipping from dict of unknown size](https://stackoverflow.com/a/40658867)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from spacy.tokens import Doc\n",
    "# from spacy.training import Example\n",
    "\n",
    "\n",
    "def txt_and_multi_cat(txt_series, multi_cat_df):\n",
    "        \n",
    "    # convert each series or series slice to list\n",
    "    t = txt_series.tolist()\n",
    "\n",
    "    \n",
    "    # get name for each dependent column\n",
    "    cats = [multi_cat_df[cat].name.upper() for cat in multi_cat_df.columns]\n",
    "    print(cats)\n",
    "    \n",
    "    \n",
    "    cat_vals = multi_cat_df.values.tolist()\n",
    "    \n",
    "    c = [{cats[i]: v for i, v in enumerate(row)} for row in cat_vals]\n",
    "    \n",
    "    \n",
    "#     for row in cat_vals:\n",
    "#         print(row)\n",
    "# #         row_cat = dict()\n",
    "        \n",
    "# #         for i, v in enumerate(row):\n",
    "# # #             print(i, v)\n",
    "# #             row_cat[cats[i]] = v\n",
    "    \n",
    "#         row_cat = {cats[i]: v for i, v in enumerate(row)}\n",
    "        \n",
    "        \n",
    "        \n",
    "#         annotations_list.append(row_cat)\n",
    "\n",
    "#     print(len(t), len(annotations_list))\n",
    "#     for i in annotations_list:\n",
    "#         print(i)\n",
    "\n",
    "    \n",
    "# def txt_and_cat(txt_series, cat_series):\n",
    "        \n",
    "#     # convert each series or series slice to list\n",
    "#     t = txt_series.tolist()\n",
    "#     c = cat_series.tolist()\n",
    "    \n",
    "#     # format categories\n",
    "#     c = [{\"TOXIC\": bool(y), \"NOT TOXIC\": not bool(y)} for y in c]\n",
    "    c = [{'cats': i} for i in c]\n",
    "    \n",
    "    docs = list(zip(t, c))\n",
    "    \n",
    "    return docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TOXIC', 'SEVERE_TOXIC', 'OBSCENE', 'THREAT', 'INSULT', 'IDENTITY_HATE']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(\"' Meša Selimović I'm not opposing such a formulation. Instead I'm trying to prevent potential editwars by inclusion of both views (Bosnian and Serbian writer). However, it seems that there is a third view (Yugoslavian writer) and so an option is to mention all of them (Yugoslavian, Bosnian and Serbian writer). Although this may read cumbersome, maybe it's worth trying. All the best. 's talk '\",\n",
       "  {'cats': {'TOXIC': 0,\n",
       "    'SEVERE_TOXIC': 0,\n",
       "    'OBSCENE': 0,\n",
       "    'THREAT': 0,\n",
       "    'INSULT': 0,\n",
       "    'IDENTITY_HATE': 0}}),\n",
       " (\"' September 2008 (UTC) Talking about how he was victimized because of the release of his name is an implication that releasing his name was bad. (talk | contribs) 03:17, 9'\",\n",
       "  {'cats': {'TOXIC': 0,\n",
       "    'SEVERE_TOXIC': 0,\n",
       "    'OBSCENE': 0,\n",
       "    'THREAT': 0,\n",
       "    'INSULT': 0,\n",
       "    'IDENTITY_HATE': 0}}),\n",
       " (', 1 August 2012 (UTC) Danke, - supports what we found, no need to ask further, - the Main page appearance on 26 July opened new heights, 08:05',\n",
       "  {'cats': {'TOXIC': 0,\n",
       "    'SEVERE_TOXIC': 0,\n",
       "    'OBSCENE': 0,\n",
       "    'THREAT': 0,\n",
       "    'INSULT': 0,\n",
       "    'IDENTITY_HATE': 0}}),\n",
       " (\"' The Aurora name One of the parts of the story that seemed particularly weak was the name. 'Aurora' was selected because it appeared as a line item in a budget document. I am currently reading a National Academy of Sciences report called 'Review of the Department of Energy’s Inertial Confinement Fusion Program', which was published in September 1990. The paper discusses a variety of issues relating to controlled fusion experiments, and led indirectly to the current National Ignition Facility efforts. Why do I mention this? Well on the very first page I found: ...and a subsequent meeting was held in La Jolla on August 21, 1990, to consider future experiments possible with the AURORA facility. Aurora was a high-power KrF ICF laser built at Los Alamos. Given the time frame, the general secrecy surrounding these machines, and the common name, is there any chance the line item in question was the budget for this laser? '\",\n",
       "  {'cats': {'TOXIC': 0,\n",
       "    'SEVERE_TOXIC': 0,\n",
       "    'OBSCENE': 0,\n",
       "    'THREAT': 0,\n",
       "    'INSULT': 0,\n",
       "    'IDENTITY_HATE': 0}}),\n",
       " (\"' WP:NOT: W is not a 'how to' Wikipedia is not a 'how to' manual. The text should not being giving out instructions about what to do when one finds oneself having symptoms of a disease or having a diagnosis of a disease. Furthermore, Wikipedia should not be givng out any medical advice at all. Please avoid phrases like 'women should...'. If a FACT is represented in some sentence that starts with 'Women should...', then please rephrase it into an objective FACT. Only licensed physicians should be saying what 'women should' do, and on some other site: NOT THIS ONE. '\",\n",
       "  {'cats': {'TOXIC': 0,\n",
       "    'SEVERE_TOXIC': 0,\n",
       "    'OBSCENE': 0,\n",
       "    'THREAT': 0,\n",
       "    'INSULT': 0,\n",
       "    'IDENTITY_HATE': 0}}),\n",
       " (\"Apology accepted, ! Mistakes happen, and in the scheme of things this one was sorted out pretty quickly, so don't feel too bad. Thanks for the apology though! Cheers, (let's chat)\",\n",
       "  {'cats': {'TOXIC': 0,\n",
       "    'SEVERE_TOXIC': 0,\n",
       "    'OBSCENE': 0,\n",
       "    'THREAT': 0,\n",
       "    'INSULT': 0,\n",
       "    'IDENTITY_HATE': 0}}),\n",
       " (\"' And you could pick any number from here . For example, 'of all the scientific journals, New Scientist has undoubtedly been the most supportive Of Sheldrake, having published a number of sympathetic articles on formative causation over the years.' '\",\n",
       "  {'cats': {'TOXIC': 0,\n",
       "    'SEVERE_TOXIC': 0,\n",
       "    'OBSCENE': 0,\n",
       "    'THREAT': 0,\n",
       "    'INSULT': 0,\n",
       "    'IDENTITY_HATE': 0}}),\n",
       " (\"' Should this be added? Should it be added on this page or the Great Britain page or both? -TC '\",\n",
       "  {'cats': {'TOXIC': 0,\n",
       "    'SEVERE_TOXIC': 0,\n",
       "    'OBSCENE': 0,\n",
       "    'THREAT': 0,\n",
       "    'INSULT': 0,\n",
       "    'IDENTITY_HATE': 0}}),\n",
       " (\"Note that according to Wikipedia's guideline on Date formatting and linking, don't link isolated years, so edits like this at Baby Phat are not necessary. Gimmetrow\",\n",
       "  {'cats': {'TOXIC': 0,\n",
       "    'SEVERE_TOXIC': 0,\n",
       "    'OBSCENE': 0,\n",
       "    'THREAT': 0,\n",
       "    'INSULT': 0,\n",
       "    'IDENTITY_HATE': 0}}),\n",
       " (\"' Hello, to begin with, nobody 'works' for Wikipedia as it is a volunteer project, but I am an adminstrator for the project. The problem that we have with the addition of text from non-free sources even by the copyright holder us that it is difficult to determine whether the person adding the text is who they claim to be or is the original author of the text; a further issue is that all edits to Wikipedia must by freely licensed and few commercial or governmental organisations are willing to do this. See, for example, your own assertion of copyright. Please also bear in mind that Wikipedia is an encyclopedia and that our content should be written with a neutral, dispassionate and scholarly tone. Text originally written for corporate promotion almost always needs to be rewritten to be appropriate for an encyclopedia. '\",\n",
       "  {'cats': {'TOXIC': 0,\n",
       "    'SEVERE_TOXIC': 0,\n",
       "    'OBSCENE': 0,\n",
       "    'THREAT': 0,\n",
       "    'INSULT': 0,\n",
       "    'IDENTITY_HATE': 0}}),\n",
       " ('Multiple versions of #11 released from diversity of sources   Via Archive.org',\n",
       "  {'cats': {'TOXIC': 0,\n",
       "    'SEVERE_TOXIC': 0,\n",
       "    'OBSCENE': 0,\n",
       "    'THREAT': 0,\n",
       "    'INSULT': 0,\n",
       "    'IDENTITY_HATE': 0}}),\n",
       " ('Plese sig your statements, if possible. Martial Law',\n",
       "  {'cats': {'TOXIC': 0,\n",
       "    'SEVERE_TOXIC': 0,\n",
       "    'OBSCENE': 0,\n",
       "    'THREAT': 0,\n",
       "    'INSULT': 0,\n",
       "    'IDENTITY_HATE': 0}}),\n",
       " (\"' I don't see any major differences between Israel and Sri Lanka to allow Sri Lanka's inclusion while excluding Israel. A couple of users have stated that Boyle is not credible so let's move on from him. The rest of the sources cited in the article are reporting claims made by fringe groups the Tamil nationalists in the diaspora. They are not 'Mainstream observers of world affairs' and are very much of the fringe, the UN and other have simply called the events in Sri Lanka war crimes and not genocide. Thus there is no basis for inclusion on this page. '\",\n",
       "  {'cats': {'TOXIC': 0,\n",
       "    'SEVERE_TOXIC': 0,\n",
       "    'OBSCENE': 0,\n",
       "    'THREAT': 0,\n",
       "    'INSULT': 0,\n",
       "    'IDENTITY_HATE': 0}}),\n",
       " (\"The article right now has it that Ami was supposed to unhuman in some way and that Osabu talked her out of it; we're just missing the specific way, which is I think that she was supposed to be a cyborg. Hence all the computer-related accessories. It's interesting, too, 'cause that same interest in having a cute cyborg girl got passed on to Hotaru eventually. ♫\",\n",
       "  {'cats': {'TOXIC': 0,\n",
       "    'SEVERE_TOXIC': 0,\n",
       "    'OBSCENE': 0,\n",
       "    'THREAT': 0,\n",
       "    'INSULT': 0,\n",
       "    'IDENTITY_HATE': 0}}),\n",
       " ('Artkos, u should stop nagging. U are like the proverbial creacked record. Maybe if you got a life other than here?',\n",
       "  {'cats': {'TOXIC': 0,\n",
       "    'SEVERE_TOXIC': 0,\n",
       "    'OBSCENE': 0,\n",
       "    'THREAT': 0,\n",
       "    'INSULT': 0,\n",
       "    'IDENTITY_HATE': 0}}),\n",
       " (\"Planning to make comback for Quagga Well it's probably not hard to believe but they're planning to bring back the quagga through cloning. Some DNA samples that were left over in some hair samples of dead quaggas from the few musuems that have some stuffed ones. My professor is really into these reintroduction programs of extinct animals so he told me about it of coarse they won't tell the public about this out loud. What do ya'll think? mcelite\",\n",
       "  {'cats': {'TOXIC': 0,\n",
       "    'SEVERE_TOXIC': 0,\n",
       "    'OBSCENE': 0,\n",
       "    'THREAT': 0,\n",
       "    'INSULT': 0,\n",
       "    'IDENTITY_HATE': 0}}),\n",
       " (\"' Fomenko's 'theory' is as FRINGE as it gets, and will not be treated as if it is a credible historical theory, because it isn't. So do not expect what you consider 'neutrality' in this article. You won't see Young earth creationism given credibility on the Age of the Earth article, so don't expect this one to mislead the reader to think that Fomenko's ideas are in any way legitimate. '\",\n",
       "  {'cats': {'TOXIC': 0,\n",
       "    'SEVERE_TOXIC': 0,\n",
       "    'OBSCENE': 0,\n",
       "    'THREAT': 0,\n",
       "    'INSULT': 0,\n",
       "    'IDENTITY_HATE': 0}}),\n",
       " ('Regis & Kelly I SURE AM GOING TO MISS YOU REGIS. CAN YOU DO ME A FAVOR ON THE AIR 1 DAY, WILL YOU KISS KELLY RIPPA ON THE MOUTH WITH A GREAT BIG KISS. I AM SURE THAT YOUR WIFE WILL NOT MIND. I REALLY WISH THAT I COULD COME & MEET, SEE YOU IN PERSON BEFORE YOU RETIRE ON NOV 18TH, 2011. TAKE GOOD CARE OF YOURSELF REGIS. EVERYONE WILL BE THINKING OFYOU EVERDAY WHEN THE SHOW IS ON. LOTS OF LUCK REGIS',\n",
       "  {'cats': {'TOXIC': 0,\n",
       "    'SEVERE_TOXIC': 0,\n",
       "    'OBSCENE': 0,\n",
       "    'THREAT': 0,\n",
       "    'INSULT': 0,\n",
       "    'IDENTITY_HATE': 0}}),\n",
       " ('Youre a sock puppet you are! you are! im going to track you down, and when i track you down, your going to drown, in your own sins. You are going to hell! I want to hell you! This is probably that pollypocket kid righting this by the way! yeah! so block the witch!',\n",
       "  {'cats': {'TOXIC': 1,\n",
       "    'SEVERE_TOXIC': 0,\n",
       "    'OBSCENE': 0,\n",
       "    'THREAT': 1,\n",
       "    'INSULT': 1,\n",
       "    'IDENTITY_HATE': 0}}),\n",
       " ('y am i writing this?!??',\n",
       "  {'cats': {'TOXIC': 0,\n",
       "    'SEVERE_TOXIC': 0,\n",
       "    'OBSCENE': 0,\n",
       "    'THREAT': 0,\n",
       "    'INSULT': 0,\n",
       "    'IDENTITY_HATE': 0}})]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot = 20\n",
    "tiny_X = X_train['comment_text'][:tot]\n",
    "tiny_y = y_train[:tot]\n",
    "\n",
    "txt_and_multi_cat(tiny_X, tiny_y)\n",
    "# print(tiny_X, tiny_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Article for v3](https://medium.com/analytics-vidhya/building-a-text-classifier-with-spacy-3-0-dd16e9979a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ! ls ../models/base_config.cfg\n",
    "# ! python -m spacy init fill-config ../models/base_config.cfg config.cfg --diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! python -m spacy validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- X columns: Index(['comment_text', 'uppercase_proportion'], dtype='object')\n",
    "y columns:Index(['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate',\n",
    "       'tuples'],\n",
    "      dtype='object') -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TOXIC', 'SEVERE_TOXIC', 'OBSCENE', 'THREAT', 'INSULT', 'IDENTITY_HATE']\n",
      "['TOXIC', 'SEVERE_TOXIC', 'OBSCENE', 'THREAT', 'INSULT', 'IDENTITY_HATE']\n"
     ]
    }
   ],
   "source": [
    "# formatting list of tuples for spacy training\n",
    "train_txt = X_train['comment_text']\n",
    "train_cat = y_train[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']]\n",
    "\n",
    "train_docs = txt_and_multi_cat(train_txt, train_cat)\n",
    "\n",
    "test_txt = X_test['comment_text']\n",
    "test_cat = y_test[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']]\n",
    "\n",
    "test_docs = txt_and_multi_cat(test_txt, test_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "' Meša Selimović I'm not oppos, {'cats': {'TOXIC': 0, 'SEVERE_TOXIC': 0, 'OBSCENE': 0, 'THREAT': 0, 'INSULT': 0, 'IDENTITY_HATE': 0}}\n",
      "' September 2008 (UTC) Talking, {'cats': {'TOXIC': 0, 'SEVERE_TOXIC': 0, 'OBSCENE': 0, 'THREAT': 0, 'INSULT': 0, 'IDENTITY_HATE': 0}}\n",
      ", 1 August 2012 (UTC) Danke, -, {'cats': {'TOXIC': 0, 'SEVERE_TOXIC': 0, 'OBSCENE': 0, 'THREAT': 0, 'INSULT': 0, 'IDENTITY_HATE': 0}}\n",
      "' The Aurora name One of the p, {'cats': {'TOXIC': 0, 'SEVERE_TOXIC': 0, 'OBSCENE': 0, 'THREAT': 0, 'INSULT': 0, 'IDENTITY_HATE': 0}}\n",
      "' WP:NOT: W is not a 'how to' , {'cats': {'TOXIC': 0, 'SEVERE_TOXIC': 0, 'OBSCENE': 0, 'THREAT': 0, 'INSULT': 0, 'IDENTITY_HATE': 0}}\n"
     ]
    }
   ],
   "source": [
    "# this should be the correct format expected by the trainer\n",
    "\n",
    "# print(train_docs[0][1])\n",
    "first_five = [i for i in train_docs[:5]]\n",
    "\n",
    "for i in first_five:\n",
    "    print(f\"{i[0][:30]}, {i[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.machinelearningplus.com/nlp/custom-text-classification-spacy\n",
    "\n",
    "# Not providing proper scoring..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import defaultdict\n",
    "\n",
    "def evaluate(tokenizer, textcat, val_texts, val_cats, thresh=0.5):\n",
    "    \n",
    "    docs = (tokenizer(val_text) for val_text in val_texts)  \n",
    "    \n",
    "    # create dict of results\n",
    "    evals_by_cat = dict()\n",
    "    \n",
    "    for i, doc in enumerate(textcat.pipe(docs)):\n",
    "        gold = val_cats[i]['cats']\n",
    "        \n",
    "        for label, score in doc.cats.items():\n",
    "            \n",
    "            # add label to dict if not already present\n",
    "            if label not in evals_by_cat:\n",
    "                evals_by_cat[label] = {'tp':0,\n",
    "                                       'fp':0,\n",
    "                                       'fn':0,\n",
    "                                       'tn':0,}\n",
    "            \n",
    "            if score >= thresh and gold[label] >= thresh:\n",
    "                evals_by_cat[label]['tp'] += 1\n",
    "\n",
    "            elif score >= thresh and gold[label] < thresh:\n",
    "                evals_by_cat[label]['fp'] += 1\n",
    "\n",
    "            elif score < thresh and gold[label] < thresh:\n",
    "                evals_by_cat[label]['tn'] += 1\n",
    "            \n",
    "            elif score < thresh and gold[label] >= thresh:\n",
    "                evals_by_cat[label]['fn'] += 1\n",
    "    \n",
    "    for key in evals_by_cat.keys():\n",
    "\n",
    "        tp = evals_by_cat[key]['tp']\n",
    "        fp = evals_by_cat[key]['fp']\n",
    "        fn = evals_by_cat[key]['fn']\n",
    "        tn = evals_by_cat[key]['tn']\n",
    "        \n",
    "        # precision\n",
    "        # edge case: avoid dividing by zero: precision = 1 when fp = 0\n",
    "        if tp + fp == 0:\n",
    "            evals_by_cat[key]['precision'] = 1\n",
    "        else:    \n",
    "            evals_by_cat[key]['precision'] = tp / (tp + fp)\n",
    "        \n",
    "        # recall\n",
    "        # edge case: avoid dividing by zero: recall = 1 when fn = 0\n",
    "        if tp + fn == 0:\n",
    "            evals_by_cat[key]['recall'] = 1\n",
    "        else:    \n",
    "            evals_by_cat[key]['recall'] = tp / (tp + fn)\n",
    "            \n",
    "        precision = evals_by_cat[key]['precision']\n",
    "        recall = evals_by_cat[key]['recall']\n",
    "        \n",
    "        if precision  + recall == 0:\n",
    "            evals_by_cat[key]['f_score'] = 0.0\n",
    "        else:\n",
    "            evals_by_cat[key]['f_score'] = 2 * (precision * recall) / (precision + recall)\n",
    "        \n",
    "    \n",
    "#     for key in evals_by_cat.keys():\n",
    "#         print(f'{key}:\\n{evals_by_cat[key]}')\n",
    "    \n",
    "#     precision = tp / (tp + fp)\n",
    "#     recall = tp / (tp + fn)\n",
    "#     if (precision + recall) == 0:\n",
    "#         f_score = 0.0\n",
    "#     else:\n",
    "#         f_score = 2 * (precision * recall) / (precision + recall)\n",
    "    evals_by_cat['TEXTCAT_LOSSES'] = losses['textcat']\n",
    "\n",
    "    return evals_by_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 1000\n",
    "train_data = train_docs[:size]\n",
    "dev_texts = [i[0] for i in test_docs[:size]]\n",
    "dev_cats = [i[1] for i in test_docs[:size]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model.\n",
      "Iterations: 2\n",
      "Timer Begins:13336.02\n",
      "epoch 1 start time: 13336.02\n",
      "textcat losses: 0.0012461869023688843\n",
      "epoch 1 end: 13337.610593877, epoch elapsed: 1.59\n",
      "\n",
      "epoch 2 start time: 13337.61\n",
      "textcat losses: 0.011721035442237682\n",
      "epoch 2 end: 13339.06375051, epoch elapsed: 1.45\n",
      "\n",
      "Training complete. End:13339.07 Training Elapsed: 3.04\n",
      "\n",
      "CPU times: user 5.64 s, sys: 4.36 s, total: 10 s\n",
      "Wall time: 3.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from spacy.util import minibatch, compounding\n",
    "\n",
    "# start = timer()\n",
    "# # ...\n",
    "# end = timer()\n",
    "# print(end - start) # Time in seconds, e.g. 5.38091952400282\n",
    "\n",
    "#(\"Number of training iterations\", \"n\", int))\n",
    "n_iter=2\n",
    "\n",
    "# Disabling other components\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'textcat']\n",
    "with nlp.disable_pipes(*other_pipes):  \n",
    "    optimizer = nlp.begin_training()\n",
    "\n",
    "    start_cumulative = timer()\n",
    "    print(f\"Training the model.\\nIterations: {n_iter}\\nTimer Begins:{start_cumulative:.2f}\")\n",
    "#     print('{:^5}\\t{:^5}\\t{:^5}\\t{:^5}'.format('LOSS', 'P', 'R', 'F'))\n",
    "\n",
    "    # Performing training\n",
    "    for i in range(n_iter):\n",
    "        start_epoch = timer()\n",
    "        print(f'epoch {i + 1} start time: {start_epoch:.2f}')\n",
    "        losses = {}\n",
    "        batches = minibatch(train_data, size=compounding(4., 32., 1.001))\n",
    "        for batch in batches:\n",
    "            texts, annotations = zip(*batch)\n",
    "            nlp.update(texts, \n",
    "                       annotations, \n",
    "                       sgd=optimizer, \n",
    "                       drop=0.2,\n",
    "                       losses=losses)\n",
    "\n",
    "      # Calling the evaluate() function and printing the scores\n",
    "        with textcat.model.use_params(optimizer.averages):\n",
    "            evals_by_cat = evaluate(nlp.tokenizer, textcat, dev_texts, dev_cats)\n",
    "            # reduced scores for testing\n",
    "            print(f'textcat losses:', losses['textcat'])\n",
    "            \n",
    "            end_epoch = timer()\n",
    "            time.strftime(\"%Hh%Mm%Ss\", time.gmtime(4*3600+13*60+6)) \n",
    "            print(f'epoch {i + 1} end: {end_epoch}, epoch elapsed: {end_epoch-start_epoch:.2f}\\n')\n",
    "         \n",
    "            \n",
    "#             for key in evals_by_cat.keys():\n",
    "#                 print(f'{key}:\\n{evals_by_cat[key]}')\n",
    "#         print('{0:.3f}\\t{1:.3f}\\t{2:.3f}\\t{3:.3f}'  \n",
    "#               .format(losses['textcat'], scores['textcat_p'],\n",
    "#                       scores['textcat_r'], scores['textcat_f']))\n",
    "\n",
    "end_cumulative = timer()\n",
    "print(f\"Training complete. End:{end_cumulative:.2f} Training Elapsed: {end_cumulative - start_cumulative:.2f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_df = pd.DataFrame.from_dict(evals_by_cat['INSULT'], orient='index', columns=['INSULT_epoch1'])\n",
    "second_df = pd.DataFrame.from_dict(evals_by_cat['TOXIC'], orient='index', columns=['TOXIC_epoch1'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INSULT_epoch1</th>\n",
       "      <th>TOXIC_epoch1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tp</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fp</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fn</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tn</th>\n",
       "      <td>92.000000</td>\n",
       "      <td>88.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.875000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f_score</th>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           INSULT_epoch1  TOXIC_epoch1\n",
       "tp              7.000000      8.000000\n",
       "fp              1.000000      0.000000\n",
       "fn              0.000000      4.000000\n",
       "tn             92.000000     88.000000\n",
       "precision       0.875000      1.000000\n",
       "recall          1.000000      0.666667\n",
       "f_score         0.933333      0.800000"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([first_df, second_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "evals_df = pd.DataFrame.from_dict(evals_by_cat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TOXIC</th>\n",
       "      <th>SEVERE_TOXIC</th>\n",
       "      <th>OBSCENE</th>\n",
       "      <th>THREAT</th>\n",
       "      <th>INSULT</th>\n",
       "      <th>IDENTITY_HATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tp</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fp</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fn</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tn</th>\n",
       "      <td>84.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>96.0</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.692308</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f_score</th>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               TOXIC  SEVERE_TOXIC    OBSCENE  THREAT     INSULT  \\\n",
       "tp          9.000000      3.000000   5.000000     0.0   7.000000   \n",
       "fp          4.000000      0.000000   2.000000     3.0   5.000000   \n",
       "fn          3.000000      1.000000   1.000000     1.0   0.000000   \n",
       "tn         84.000000     96.000000  92.000000    96.0  88.000000   \n",
       "precision   0.692308      1.000000   0.714286     0.0   0.583333   \n",
       "recall      0.750000      0.750000   0.833333     0.0   1.000000   \n",
       "f_score     0.720000      0.857143   0.769231     0.0   0.736842   \n",
       "\n",
       "           IDENTITY_HATE  \n",
       "tp                   0.0  \n",
       "fp                   1.0  \n",
       "fn                   4.0  \n",
       "tn                  95.0  \n",
       "precision            0.0  \n",
       "recall               0.0  \n",
       "f_score              0.0  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "one_text = dev_texts[11]\n",
    "# one_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "' Ok, let me say it again Come on, now you guys are just being piece of shit jews. I mean you have to admit, the guys in pink floyd play their instruments about as slow as a nigger works. I shouldn't even call what they play music. It's just a bunch of alarm clocks and cashier regirsters! But you know what the most pretentious thing about them is, its their lyrics. All af their songs are just surrealist poetry sung over doom-noise pop, and everyone starts calling them genius's over it. The truth is, their songs have no meaning. Take the album 'The Wall' for instance; sure it tells a story, but what is the moral and the meaning of the story? And dont tell me that the purpose of their songs is to make you think. The only way that music as slow as pink floyd could make you fucking think is if you were just as stoned as they are, which you kikes probly are... And one last time: 1) pink floyd fucking sucks 2) david fuckmor should taste my ass 3) you should to'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'TOXIC': 0.9091559052467346,\n",
       " 'SEVERE_TOXIC': 0.0608687661588192,\n",
       " 'OBSCENE': 0.7635753154754639,\n",
       " 'THREAT': 0.007229546085000038,\n",
       " 'INSULT': 0.5386186242103577,\n",
       " 'IDENTITY_HATE': 0.08038196712732315}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(one_text)\n",
    "\n",
    "doc=nlp(one_text)\n",
    "doc.cats \n",
    "\n",
    "# sentiment_sum = sum([i.sentiment for i in doc])\n",
    "# print(sentiment_sum)\n",
    "# doc[0].vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['meša',\n",
       " 'selimović',\n",
       " 'oppose',\n",
       " 'formulation',\n",
       " 'instead',\n",
       " 'try',\n",
       " 'prevent',\n",
       " 'potential',\n",
       " 'editwar',\n",
       " 'inclusion',\n",
       " 'view',\n",
       " 'bosnian',\n",
       " 'serbian',\n",
       " 'writer',\n",
       " 'view',\n",
       " 'yugoslavian',\n",
       " 'writer',\n",
       " 'option',\n",
       " 'mention',\n",
       " 'yugoslavian',\n",
       " 'bosnian',\n",
       " 'serbian',\n",
       " 'writer',\n",
       " 'read',\n",
       " 'cumbersome',\n",
       " 'maybe',\n",
       " 'worth',\n",
       " 'try',\n",
       " 'good',\n",
       " 'talk']"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def doc_check(tok):\n",
    "    '''\n",
    "    helper function for getting only desired lemmas from spaCy doc\n",
    "    argument: doc.token\n",
    "    \n",
    "    checks for rejection conditions\n",
    "        not alpha\n",
    "        pronoun\n",
    "        stopword\n",
    "        \n",
    "    returns True if no rejection conditions are met\n",
    "    \n",
    "    ''' \n",
    "    # reject if not alpha\n",
    "    if tok.is_alpha == False:\n",
    "        return False\n",
    "    \n",
    "    # reject if pronoun\n",
    "    if tok.lemma_ == \"-PRON-\":\n",
    "        return False\n",
    "    \n",
    "    # reject if stopword\n",
    "    if tok.is_stop == True:\n",
    "        return False\n",
    "\n",
    "    # if not rejected, return true\n",
    "    return True\n",
    "\n",
    "lemmas_lc = [i.lemma_.lower() for i in doc if doc_check(i)]\n",
    "lemmas_lc\n",
    "\n",
    "# sentiment_sum = sum([i.sentiment for i in doc])\n",
    "# print(sentiment_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[expanding contractions](https://gist.github.com/widiger-anna/deefac010da426911381c118a97fc23f) \n",
    "[contractions](https://theslaps.medium.com/cant-stand-don-t-want-contractions-with-spacy-39715cac2ebb)  \n",
    "\n",
    "\n",
    "[text wrangling](https://www.kdnuggets.com/2018/08/practitioners-guide-processing-understanding-text-2.html)  \n",
    "\n",
    "\n",
    "[nlp nltk vs spacy](https://www.activestate.com/blog/natural-language-processing-nltk-vs-spacy/)  \n",
    "\n",
    "[pytorch](https://pytorch.org/https://pytorch.org/)  \n",
    "\n",
    "[text classification in python with spacy (try this one!)](https://www.dataquest.io/blog/tutorial-text-classification-in-python-using-spacy/https://www.dataquest.io/blog/tutorial-text-classification-in-python-using-spacy/)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/machine-learning-nlp-text-classification-using-scikit-learn-python-and-nltk-c52b92a7c73a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_config.cfg       \u001b[1m\u001b[36mspacy_multi_cat_model\u001b[m\u001b[m\n",
      "base_config.cfg       \u001b[1m\u001b[36mspacy_multi_cat_model\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "! ls ../models\n",
    "nlp.to_disk(\"../models/spacy_multi_cat_model/\")\n",
    "! ls ../models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config.cfg.txt                        part_2-2_nltk.ipynb\n",
      "part_1-1_preparation_toxic_text.ipynb part_2-2_spacy_multi_cat_test.ipynb\n",
      "part_2-1_spacy_toxic_text.ipynb       part_2-3_spacy_multi_cat_test.ipynb\n"
     ]
    }
   ],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_config.cfg \u001b[1m\u001b[36mner\u001b[m\u001b[m             \u001b[1m\u001b[36mtagger\u001b[m\u001b[m          tokenizer\n",
      "meta.json       \u001b[1m\u001b[36mparser\u001b[m\u001b[m          \u001b[1m\u001b[36mtextcat\u001b[m\u001b[m         \u001b[1m\u001b[36mvocab\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "! ls ../models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOCF+j+08tL5QgwPVB141nM",
   "collapsed_sections": [],
   "name": "toxic_text.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
